{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "psychological-alarm",
   "metadata": {},
   "source": [
    "## Importing Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unnecessary-pressing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:42.520625Z",
     "start_time": "2021-03-28T20:32:42.518920Z"
    }
   },
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "## I recommend the one above, because the following is more accurate but less efficient\n",
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "frank-monaco",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:43.990040Z",
     "start_time": "2021-03-28T20:32:42.522741Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# You can also load en_core_web_lg that has an higher accuracy but it's less efficient\n",
    "# nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brutal-usage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:43.994556Z",
     "start_time": "2021-03-28T20:32:43.991087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x7f7ba335fae0>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x7f7ba33404f0>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x7f7ba3551f40>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x7f7ba3698ee0>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x7f7ba3330980>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x7f7ba331ffc0>)]\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "marine-rescue",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.015363Z",
     "start_time": "2021-03-28T20:32:43.995410Z"
    }
   },
   "outputs": [],
   "source": [
    "# Process sentences 'Hello, world. Antonio is learning Python.' using spaCy\n",
    "doc = nlp(u\"Hello, world. Antonio is learning Python.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "behavioral-prospect",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.021660Z",
     "start_time": "2021-03-28T20:32:44.016337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      ",\n",
      "world\n",
      ".\n",
      "Antonio\n",
      "is\n",
      "learning\n",
      "Python\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fleet-shooting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.030363Z",
     "start_time": "2021-03-28T20:32:44.022649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hello, world.\n",
      "Antonio is learning Python.\n"
     ]
    }
   ],
   "source": [
    "# Get first token of the processed document\n",
    "token = doc[0]\n",
    "print(token)\n",
    "\n",
    "# Print sentences (one sentence per line)\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "phantom-intranet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.043811Z",
     "start_time": "2021-03-28T20:32:44.033898Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens = nlp(\"Let's go to N.Y.!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "designed-capitol",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.049403Z",
     "start_time": "2021-03-28T20:32:44.045680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-duplicate",
   "metadata": {},
   "source": [
    "As you have seen, using `nlp`, that comes from `spacy.load(\"en_core_web_sm\")`, you get the tokenized version of the sentence. If you want only the instance of the `Tokenizer` class, you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accomplished-marker",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.054850Z",
     "start_time": "2021-03-28T20:32:44.050350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokenizer.Tokenizer"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nlp.tokenizer\n",
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-medium",
   "metadata": {},
   "source": [
    "If you want to instantiate a custom one, with rules and prefixes and so on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "olive-mother",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.062007Z",
     "start_time": "2021-03-28T20:32:44.055855Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(vocab=nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-clerk",
   "metadata": {},
   "source": [
    "The tokenizer defined above contains only english rules.\n",
    "Let's test it on \"Let's go to N.Y.!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distinct-trade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.068307Z",
     "start_time": "2021-03-28T20:32:44.063416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's\n",
      "go\n",
      "to\n",
      "N.Y.!\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(\"Let's go to N.Y.!\")\n",
    "for token in tokens:\n",
    "    print(token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-county",
   "metadata": {},
   "source": [
    "As you can see here, it doesn't handle the exceptions about the dots. So we can add rules for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "opposed-confusion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.076430Z",
     "start_time": "2021-03-28T20:32:44.069248Z"
    }
   },
   "outputs": [],
   "source": [
    "prefix_re = spacy.util.compile_prefix_regex(nlp.Defaults.prefixes)\n",
    "suffix_re = spacy.util.compile_suffix_regex(nlp.Defaults.prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "foster-highway",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.083023Z",
     "start_time": "2021-03-28T20:32:44.077855Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(\n",
    "    vocab=nlp.vocab, prefix_search=prefix_re.search, suffix_search=suffix_re.search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adjacent-organ",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.088977Z",
     "start_time": "2021-03-28T20:32:44.083988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(\"Let's go to N.Y.!\")\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-provincial",
   "metadata": {},
   "source": [
    "You can also check the exceptions the tokenizer can handle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "exposed-compound",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.103258Z",
     "start_time": "2021-03-28T20:32:44.092331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[{65: ' '}], [{65: '\\t'}], [{65: '\\\\t'}], [{65: '\\n'}], [{65: '\\\\n'}], [{65: '—'}], [{65: '\\xa0', 67: '  '}], [{65: \"'\"}], [{65: '\\\\\")'}], [{65: '<space>'}], [{65: \"''\"}], [{65: 'C++'}], [{65: 'a.'}], [{65: 'b.'}], [{65: 'c.'}], [{65: 'd.'}], [{65: 'e.'}], [{65: 'f.'}], [{65: 'g.'}], [{65: 'h.'}], [{65: 'i.'}], [{65: 'j.'}], [{65: 'k.'}], [{65: 'l.'}], [{65: 'm.'}], [{65: 'n.'}], [{65: 'o.'}], [{65: 'p.'}], [{65: 'q.'}], [{65: 'r.'}], [{65: 's.'}], [{65: 't.'}], [{65: 'u.'}], [{65: 'v.'}], [{65: 'w.'}], [{65: 'x.'}], [{65: 'y.'}], [{65: 'z.'}], [{65: 'ä.'}], [{65: 'ö.'}], [{65: 'ü.'}], [{65: 'O.O'}], [{65: 'XDD'}], [{65: '(-_-)'}], [{65: '=|'}], [{65: 'xDD'}], [{65: '(>_<)'}], [{65: 'ಠ_ಠ'}], [{65: ':-O'}], [{65: ':-)'}], [{65: '^___^'}], [{65: 'ಠ︵ಠ'}], [{65: ':-(('}], [{65: ':-p'}], [{65: ':-((('}], [{65: ':('}], [{65: ':x'}], [{65: '<3'}], [{65: ')-:'}], [{65: '(ಠ_ಠ)'}], [{65: ':-x'}], [{65: '[-:'}], [{65: ';-)'}], [{65: ':-o'}], [{65: ';-D'}], [{65: ':3'}], [{65: '(╯°□°）╯︵┻━┻'}], [{65: '(._.)'}], [{65: ';_;'}], [{65: ':*'}], [{65: 'o.O'}], [{65: ':o)'}], [{65: '<33'}], [{65: ':-|'}], [{65: '>.<'}], [{65: 'O_O'}], [{65: 'o_o'}], [{65: '<.<'}], [{65: 'V.V'}], [{65: ':-P'}], [{65: ':p'}], [{65: '=)'}], [{65: ':-3'}], [{65: ':D'}], [{65: '=]'}], [{65: '(-:'}], [{65: '8D'}], [{65: ':X'}], [{65: '._.'}], [{65: '[:'}], [{65: 'O_o'}], [{65: ':-X'}], [{65: '0.0'}], [{65: '(-8'}], [{65: '(:'}], [{65: ':1'}], [{65: ':-0'}], [{65: ';)'}], [{65: '0.o'}], [{65: '^__^'}], [{65: ':-]'}], [{65: \":')\"}], [{65: '0_o'}], [{65: ':/'}], [{65: 'o.o'}], [{65: '(¬_¬)'}], [{65: 'v.v'}], [{65: ':-('}], [{65: '-_-'}], [{65: '=('}], [{65: 'o.0'}], [{65: ':()'}], [{65: ':-)))'}], [{65: '(*_*)'}], [{65: '><(((*>'}], [{65: '>:o'}], [{65: 'v_v'}], [{65: ':((('}], [{65: ':>'}], [{65: '=D'}], [{65: '=3'}], [{65: '8-)'}], [{65: '^_^'}], [{65: ':|'}], [{65: ':o'}], [{65: '(;'}], [{65: '8)'}], [{65: ':-))'}], [{65: 'o_0'}], [{65: ':-*'}], [{65: ':(('}], [{65: ':))'}], [{65: \":'-(\"}], [{65: ':)))'}], [{65: ';D'}], [{65: '(o:'}], [{65: 'xD'}], [{65: 'o_O'}], [{65: ':O'}], [{65: ':-/'}], [{65: '-__-'}], [{65: '(-;'}], [{65: ':-}'}], [{65: '=/'}], [{65: '0_0'}], [{65: \":'-)\"}], [{65: '):'}], [{65: '(^_^)'}], [{65: 'V_V'}], [{65: '(='}], [{65: ':P'}], [{65: ':}'}], [{65: \":'(\"}], [{65: 'O.o'}], [{65: ']='}], [{65: ':->'}], [{65: '@_@'}], [{65: ':0'}], [{65: '<333'}], [{65: '8-D'}], [{65: '¯\\\\(ツ)/¯'}], [{65: ':)'}], [{65: '=['}], [{65: '[='}], [{65: ':]'}], [{65: '>:('}], [{65: '</3'}], [{65: 'XD'}], [{65: ':-D'}], [{65: '>.>'}], [{65: 'i', 67: 'i'}, {65: \"'m\", 67: 'am'}], [{65: 'i', 67: 'i'}, {65: 'm'}], [{65: 'i', 67: 'i'}, {65: \"'m\", 67: 'am'}, {65: 'a', 67: 'gonna'}], [{65: 'i', 67: 'i'}, {65: 'm', 67: 'am'}, {65: 'a', 67: 'gonna'}], [{65: 'I', 67: 'i'}, {65: \"'m\", 67: 'am'}], [{65: 'I', 67: 'i'}, {65: 'm'}], [{65: 'I', 67: 'i'}, {65: \"'m\", 67: 'am'}, {65: 'a', 67: 'gonna'}], [{65: 'I', 67: 'i'}, {65: 'm', 67: 'am'}, {65: 'a', 67: 'gonna'}], [{65: 'i', 67: 'i'}, {65: \"'ll\", 67: 'will'}], [{65: 'i', 67: 'i'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'i', 67: 'i'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'i', 67: 'i'}, {65: \"'d\", 67: \"'d\"}], [{65: 'i', 67: 'i'}, {65: 'd', 67: \"'d\"}], [{65: 'i', 67: 'i'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'i', 67: 'i'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'I', 67: 'i'}, {65: \"'ll\", 67: 'will'}], [{65: 'I', 67: 'i'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'I', 67: 'i'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'I', 67: 'i'}, {65: \"'d\", 67: \"'d\"}], [{65: 'I', 67: 'i'}, {65: 'd', 67: \"'d\"}], [{65: 'I', 67: 'i'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'I', 67: 'i'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'you', 67: 'you'}, {65: \"'ll\", 67: 'will'}], [{65: 'you', 67: 'you'}, {65: 'll', 67: 'will'}], [{65: 'you', 67: 'you'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'you', 67: 'you'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'you', 67: 'you'}, {65: \"'d\", 67: \"'d\"}], [{65: 'you', 67: 'you'}, {65: 'd', 67: \"'d\"}], [{65: 'you', 67: 'you'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'you', 67: 'you'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'You', 67: 'you'}, {65: \"'ll\", 67: 'will'}], [{65: 'You', 67: 'you'}, {65: 'll', 67: 'will'}], [{65: 'You', 67: 'you'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'You', 67: 'you'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'You', 67: 'you'}, {65: \"'d\", 67: \"'d\"}], [{65: 'You', 67: 'you'}, {65: 'd', 67: \"'d\"}], [{65: 'You', 67: 'you'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'You', 67: 'you'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'he', 67: 'he'}, {65: \"'ll\", 67: 'will'}], [{65: 'he', 67: 'he'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'he', 67: 'he'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'he', 67: 'he'}, {65: \"'d\", 67: \"'d\"}], [{65: 'he', 67: 'he'}, {65: 'd', 67: \"'d\"}], [{65: 'he', 67: 'he'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'he', 67: 'he'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'He', 67: 'he'}, {65: \"'ll\", 67: 'will'}], [{65: 'He', 67: 'he'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'He', 67: 'he'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'He', 67: 'he'}, {65: \"'d\", 67: \"'d\"}], [{65: 'He', 67: 'he'}, {65: 'd', 67: \"'d\"}], [{65: 'He', 67: 'he'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'He', 67: 'he'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'she', 67: 'she'}, {65: \"'ll\", 67: 'will'}], [{65: 'she', 67: 'she'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'she', 67: 'she'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'she', 67: 'she'}, {65: \"'d\", 67: \"'d\"}], [{65: 'she', 67: 'she'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'she', 67: 'she'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'She', 67: 'she'}, {65: \"'ll\", 67: 'will'}], [{65: 'She', 67: 'she'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'She', 67: 'she'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'She', 67: 'she'}, {65: \"'d\", 67: \"'d\"}], [{65: 'She', 67: 'she'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'She', 67: 'she'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'it', 67: 'it'}, {65: \"'ll\", 67: 'will'}], [{65: 'it', 67: 'it'}, {65: 'll', 67: 'will'}], [{65: 'it', 67: 'it'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'it', 67: 'it'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'it', 67: 'it'}, {65: \"'d\", 67: \"'d\"}], [{65: 'it', 67: 'it'}, {65: 'd', 67: \"'d\"}], [{65: 'it', 67: 'it'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'it', 67: 'it'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'It', 67: 'it'}, {65: \"'ll\", 67: 'will'}], [{65: 'It', 67: 'it'}, {65: 'll', 67: 'will'}], [{65: 'It', 67: 'it'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'It', 67: 'it'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'It', 67: 'it'}, {65: \"'d\", 67: \"'d\"}], [{65: 'It', 67: 'it'}, {65: 'd', 67: \"'d\"}], [{65: 'It', 67: 'it'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'It', 67: 'it'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'we', 67: 'we'}, {65: \"'ll\", 67: 'will'}], [{65: 'we', 67: 'we'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'we', 67: 'we'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'we', 67: 'we'}, {65: \"'d\", 67: \"'d\"}], [{65: 'we', 67: 'we'}, {65: 'd', 67: \"'d\"}], [{65: 'we', 67: 'we'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'we', 67: 'we'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'We', 67: 'we'}, {65: \"'ll\", 67: 'will'}], [{65: 'We', 67: 'we'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'We', 67: 'we'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'We', 67: 'we'}, {65: \"'d\", 67: \"'d\"}], [{65: 'We', 67: 'we'}, {65: 'd', 67: \"'d\"}], [{65: 'We', 67: 'we'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'We', 67: 'we'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'they', 67: 'they'}, {65: \"'ll\", 67: 'will'}], [{65: 'they', 67: 'they'}, {65: 'll', 67: 'will'}], [{65: 'they', 67: 'they'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'they', 67: 'they'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'they', 67: 'they'}, {65: \"'d\", 67: \"'d\"}], [{65: 'they', 67: 'they'}, {65: 'd', 67: \"'d\"}], [{65: 'they', 67: 'they'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'they', 67: 'they'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'They', 67: 'they'}, {65: \"'ll\", 67: 'will'}], [{65: 'They', 67: 'they'}, {65: 'll', 67: 'will'}], [{65: 'They', 67: 'they'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'They', 67: 'they'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'They', 67: 'they'}, {65: \"'d\", 67: \"'d\"}], [{65: 'They', 67: 'they'}, {65: 'd', 67: \"'d\"}], [{65: 'They', 67: 'they'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'They', 67: 'they'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'i', 67: 'i'}, {65: \"'ve\", 67: 'have'}], [{65: 'i', 67: 'i'}, {65: 've', 67: 'have'}], [{65: 'I', 67: 'i'}, {65: \"'ve\", 67: 'have'}], [{65: 'I', 67: 'i'}, {65: 've', 67: 'have'}], [{65: 'you', 67: 'you'}, {65: \"'ve\", 67: 'have'}], [{65: 'you', 67: 'you'}, {65: 've', 67: 'have'}], [{65: 'You', 67: 'you'}, {65: \"'ve\", 67: 'have'}], [{65: 'You', 67: 'you'}, {65: 've', 67: 'have'}], [{65: 'we', 67: 'we'}, {65: \"'ve\", 67: 'have'}], [{65: 'we', 67: 'we'}, {65: 've', 67: 'have'}], [{65: 'We', 67: 'we'}, {65: \"'ve\", 67: 'have'}], [{65: 'We', 67: 'we'}, {65: 've', 67: 'have'}], [{65: 'they', 67: 'they'}, {65: \"'ve\", 67: 'have'}], [{65: 'they', 67: 'they'}, {65: 've', 67: 'have'}], [{65: 'They', 67: 'they'}, {65: \"'ve\", 67: 'have'}], [{65: 'They', 67: 'they'}, {65: 've', 67: 'have'}], [{65: 'you', 67: 'you'}, {65: \"'re\", 67: 'are'}], [{65: 'you', 67: 'you'}, {65: 're', 67: 'are'}], [{65: 'You', 67: 'you'}, {65: \"'re\", 67: 'are'}], [{65: 'You', 67: 'you'}, {65: 're', 67: 'are'}], [{65: 'we', 67: 'we'}, {65: \"'re\", 67: 'are'}], [{65: 'We', 67: 'we'}, {65: \"'re\", 67: 'are'}], [{65: 'they', 67: 'they'}, {65: \"'re\", 67: 'are'}], [{65: 'they', 67: 'they'}, {65: 're', 67: 'are'}], [{65: 'They', 67: 'they'}, {65: \"'re\", 67: 'are'}], [{65: 'They', 67: 'they'}, {65: 're', 67: 'are'}], [{65: 'he', 67: 'he'}, {65: \"'s\", 67: \"'s\"}], [{65: 'he', 67: 'he'}, {65: 's'}], [{65: 'He', 67: 'he'}, {65: \"'s\", 67: \"'s\"}], [{65: 'He', 67: 'he'}, {65: 's'}], [{65: 'she', 67: 'she'}, {65: \"'s\", 67: \"'s\"}], [{65: 'she', 67: 'she'}, {65: 's'}], [{65: 'She', 67: 'she'}, {65: \"'s\", 67: \"'s\"}], [{65: 'She', 67: 'she'}, {65: 's'}], [{65: 'it', 67: 'it'}, {65: \"'s\", 67: \"'s\"}], [{65: 'It', 67: 'it'}, {65: \"'s\", 67: \"'s\"}], [{65: 'who', 67: 'who'}, {65: \"'s\", 67: \"'s\"}], [{65: 'who', 67: 'who'}, {65: 's'}], [{65: 'who', 67: 'who'}, {65: \"'ll\", 67: 'will'}], [{65: 'who', 67: 'who'}, {65: 'll', 67: 'will'}], [{65: 'who', 67: 'who'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'who', 67: 'who'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'who', 67: 'who'}, {65: \"'re\", 67: 'are'}], [{65: 'who', 67: 'who'}, {65: \"'ve\"}], [{65: 'who'}, {65: 've', 67: 'have'}], [{65: 'who', 67: 'who'}, {65: \"'d\", 67: \"'d\"}], [{65: 'who', 67: 'who'}, {65: 'd', 67: \"'d\"}], [{65: 'who', 67: 'who'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'who', 67: 'who'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'Who', 67: 'who'}, {65: \"'s\", 67: \"'s\"}], [{65: 'Who', 67: 'who'}, {65: 's'}], [{65: 'Who', 67: 'who'}, {65: \"'ll\", 67: 'will'}], [{65: 'Who', 67: 'who'}, {65: 'll', 67: 'will'}], [{65: 'Who', 67: 'who'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'Who', 67: 'who'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'Who', 67: 'who'}, {65: \"'re\", 67: 'are'}], [{65: 'Who', 67: 'who'}, {65: \"'ve\"}], [{65: 'Who'}, {65: 've', 67: 'have'}], [{65: 'Who', 67: 'who'}, {65: \"'d\", 67: \"'d\"}], [{65: 'Who', 67: 'who'}, {65: 'd', 67: \"'d\"}], [{65: 'Who', 67: 'who'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'Who', 67: 'who'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'what', 67: 'what'}, {65: \"'s\", 67: \"'s\"}], [{65: 'what', 67: 'what'}, {65: 's'}], [{65: 'what', 67: 'what'}, {65: \"'ll\", 67: 'will'}], [{65: 'what', 67: 'what'}, {65: 'll', 67: 'will'}], [{65: 'what', 67: 'what'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'what', 67: 'what'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'what', 67: 'what'}, {65: \"'re\", 67: 'are'}], [{65: 'what', 67: 'what'}, {65: 're', 67: 'are'}], [{65: 'what', 67: 'what'}, {65: \"'ve\"}], [{65: 'what'}, {65: 've', 67: 'have'}], [{65: 'what', 67: 'what'}, {65: \"'d\", 67: \"'d\"}], [{65: 'what', 67: 'what'}, {65: 'd', 67: \"'d\"}], [{65: 'what', 67: 'what'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'what', 67: 'what'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'What', 67: 'what'}, {65: \"'s\", 67: \"'s\"}], [{65: 'What', 67: 'what'}, {65: 's'}], [{65: 'What', 67: 'what'}, {65: \"'ll\", 67: 'will'}], [{65: 'What', 67: 'what'}, {65: 'll', 67: 'will'}], [{65: 'What', 67: 'what'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'What', 67: 'what'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'What', 67: 'what'}, {65: \"'re\", 67: 'are'}], [{65: 'What', 67: 'what'}, {65: 're', 67: 'are'}], [{65: 'What', 67: 'what'}, {65: \"'ve\"}], [{65: 'What'}, {65: 've', 67: 'have'}], [{65: 'What', 67: 'what'}, {65: \"'d\", 67: \"'d\"}], [{65: 'What', 67: 'what'}, {65: 'd', 67: \"'d\"}], [{65: 'What', 67: 'what'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'What', 67: 'what'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'when', 67: 'when'}, {65: \"'s\", 67: \"'s\"}], [{65: 'when', 67: 'when'}, {65: 's'}], [{65: 'when', 67: 'when'}, {65: \"'ll\", 67: 'will'}], [{65: 'when', 67: 'when'}, {65: 'll', 67: 'will'}], [{65: 'when', 67: 'when'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'when', 67: 'when'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'when', 67: 'when'}, {65: \"'re\", 67: 'are'}], [{65: 'when', 67: 'when'}, {65: 're', 67: 'are'}], [{65: 'when', 67: 'when'}, {65: \"'ve\"}], [{65: 'when'}, {65: 've', 67: 'have'}], [{65: 'when', 67: 'when'}, {65: \"'d\", 67: \"'d\"}], [{65: 'when', 67: 'when'}, {65: 'd', 67: \"'d\"}], [{65: 'when', 67: 'when'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'when', 67: 'when'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'When', 67: 'when'}, {65: \"'s\", 67: \"'s\"}], [{65: 'When', 67: 'when'}, {65: 's'}], [{65: 'When', 67: 'when'}, {65: \"'ll\", 67: 'will'}], [{65: 'When', 67: 'when'}, {65: 'll', 67: 'will'}], [{65: 'When', 67: 'when'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'When', 67: 'when'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'When', 67: 'when'}, {65: \"'re\", 67: 'are'}], [{65: 'When', 67: 'when'}, {65: 're', 67: 'are'}], [{65: 'When', 67: 'when'}, {65: \"'ve\"}], [{65: 'When'}, {65: 've', 67: 'have'}], [{65: 'When', 67: 'when'}, {65: \"'d\", 67: \"'d\"}], [{65: 'When', 67: 'when'}, {65: 'd', 67: \"'d\"}], [{65: 'When', 67: 'when'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'When', 67: 'when'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'where', 67: 'where'}, {65: \"'s\", 67: \"'s\"}], [{65: 'where', 67: 'where'}, {65: 's'}], [{65: 'where', 67: 'where'}, {65: \"'ll\", 67: 'will'}], [{65: 'where', 67: 'where'}, {65: 'll', 67: 'will'}], [{65: 'where', 67: 'where'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'where', 67: 'where'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'where', 67: 'where'}, {65: \"'re\", 67: 'are'}], [{65: 'where', 67: 'where'}, {65: 're', 67: 'are'}], [{65: 'where', 67: 'where'}, {65: \"'ve\"}], [{65: 'where'}, {65: 've', 67: 'have'}], [{65: 'where', 67: 'where'}, {65: \"'d\", 67: \"'d\"}], [{65: 'where', 67: 'where'}, {65: 'd', 67: \"'d\"}], [{65: 'where', 67: 'where'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'where', 67: 'where'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'Where', 67: 'where'}, {65: \"'s\", 67: \"'s\"}], [{65: 'Where', 67: 'where'}, {65: 's'}], [{65: 'Where', 67: 'where'}, {65: \"'ll\", 67: 'will'}], [{65: 'Where', 67: 'where'}, {65: 'll', 67: 'will'}], [{65: 'Where', 67: 'where'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'Where', 67: 'where'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'Where', 67: 'where'}, {65: \"'re\", 67: 'are'}], [{65: 'Where', 67: 'where'}, {65: 're', 67: 'are'}], [{65: 'Where', 67: 'where'}, {65: \"'ve\"}], [{65: 'Where'}, {65: 've', 67: 'have'}], [{65: 'Where', 67: 'where'}, {65: \"'d\", 67: \"'d\"}], [{65: 'Where', 67: 'where'}, {65: 'd', 67: \"'d\"}], [{65: 'Where', 67: 'where'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'Where', 67: 'where'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'why', 67: 'why'}, {65: \"'s\", 67: \"'s\"}], [{65: 'why', 67: 'why'}, {65: 's'}], [{65: 'why', 67: 'why'}, {65: \"'ll\", 67: 'will'}], [{65: 'why', 67: 'why'}, {65: 'll', 67: 'will'}], [{65: 'why', 67: 'why'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'why', 67: 'why'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'why', 67: 'why'}, {65: \"'re\", 67: 'are'}], [{65: 'why', 67: 'why'}, {65: 're', 67: 'are'}], [{65: 'why', 67: 'why'}, {65: \"'ve\"}], [{65: 'why'}, {65: 've', 67: 'have'}], [{65: 'why', 67: 'why'}, {65: \"'d\", 67: \"'d\"}], [{65: 'why', 67: 'why'}, {65: 'd', 67: \"'d\"}], [{65: 'why', 67: 'why'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'why', 67: 'why'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'Why', 67: 'why'}, {65: \"'s\", 67: \"'s\"}], [{65: 'Why', 67: 'why'}, {65: 's'}], [{65: 'Why', 67: 'why'}, {65: \"'ll\", 67: 'will'}], [{65: 'Why', 67: 'why'}, {65: 'll', 67: 'will'}], [{65: 'Why', 67: 'why'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'Why', 67: 'why'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'Why', 67: 'why'}, {65: \"'re\", 67: 'are'}], [{65: 'Why', 67: 'why'}, {65: 're', 67: 'are'}], [{65: 'Why', 67: 'why'}, {65: \"'ve\"}], [{65: 'Why'}, {65: 've', 67: 'have'}], [{65: 'Why', 67: 'why'}, {65: \"'d\", 67: \"'d\"}], [{65: 'Why', 67: 'why'}, {65: 'd', 67: \"'d\"}], [{65: 'Why', 67: 'why'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'Why', 67: 'why'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'how', 67: 'how'}, {65: \"'s\", 67: \"'s\"}], [{65: 'how', 67: 'how'}, {65: 's'}], [{65: 'how', 67: 'how'}, {65: \"'ll\", 67: 'will'}], [{65: 'how', 67: 'how'}, {65: 'll', 67: 'will'}], [{65: 'how', 67: 'how'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'how', 67: 'how'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'how', 67: 'how'}, {65: \"'re\", 67: 'are'}], [{65: 'how', 67: 'how'}, {65: 're', 67: 'are'}], [{65: 'how', 67: 'how'}, {65: \"'ve\"}], [{65: 'how'}, {65: 've', 67: 'have'}], [{65: 'how', 67: 'how'}, {65: \"'d\", 67: \"'d\"}], [{65: 'how', 67: 'how'}, {65: 'd', 67: \"'d\"}], [{65: 'how', 67: 'how'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'how', 67: 'how'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'How', 67: 'how'}, {65: \"'s\", 67: \"'s\"}], [{65: 'How', 67: 'how'}, {65: 's'}], [{65: 'How', 67: 'how'}, {65: \"'ll\", 67: 'will'}], [{65: 'How', 67: 'how'}, {65: 'll', 67: 'will'}], [{65: 'How', 67: 'how'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'How', 67: 'how'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'How', 67: 'how'}, {65: \"'re\", 67: 'are'}], [{65: 'How', 67: 'how'}, {65: 're', 67: 'are'}], [{65: 'How', 67: 'how'}, {65: \"'ve\"}], [{65: 'How'}, {65: 've', 67: 'have'}], [{65: 'How', 67: 'how'}, {65: \"'d\", 67: \"'d\"}], [{65: 'How', 67: 'how'}, {65: 'd', 67: \"'d\"}], [{65: 'How', 67: 'how'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'How', 67: 'how'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'there', 67: 'there'}, {65: \"'s\", 67: \"'s\"}], [{65: 'there', 67: 'there'}, {65: 's'}], [{65: 'there', 67: 'there'}, {65: \"'ll\", 67: 'will'}], [{65: 'there', 67: 'there'}, {65: 'll', 67: 'will'}], [{65: 'there', 67: 'there'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'there', 67: 'there'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'there', 67: 'there'}, {65: \"'re\", 67: 'are'}], [{65: 'there', 67: 'there'}, {65: 're', 67: 'are'}], [{65: 'there', 67: 'there'}, {65: \"'ve\"}], [{65: 'there'}, {65: 've', 67: 'have'}], [{65: 'there', 67: 'there'}, {65: \"'d\", 67: \"'d\"}], [{65: 'there', 67: 'there'}, {65: 'd', 67: \"'d\"}], [{65: 'there', 67: 'there'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'there', 67: 'there'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'There', 67: 'there'}, {65: \"'s\", 67: \"'s\"}], [{65: 'There', 67: 'there'}, {65: 's'}], [{65: 'There', 67: 'there'}, {65: \"'ll\", 67: 'will'}], [{65: 'There', 67: 'there'}, {65: 'll', 67: 'will'}], [{65: 'There', 67: 'there'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'There', 67: 'there'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'There', 67: 'there'}, {65: \"'re\", 67: 'are'}], [{65: 'There', 67: 'there'}, {65: 're', 67: 'are'}], [{65: 'There', 67: 'there'}, {65: \"'ve\"}], [{65: 'There'}, {65: 've', 67: 'have'}], [{65: 'There', 67: 'there'}, {65: \"'d\", 67: \"'d\"}], [{65: 'There', 67: 'there'}, {65: 'd', 67: \"'d\"}], [{65: 'There', 67: 'there'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'There', 67: 'there'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'that', 67: 'that'}, {65: \"'s\", 67: \"'s\"}], [{65: 'that', 67: 'that'}, {65: 's'}], [{65: 'that', 67: 'that'}, {65: \"'ll\", 67: 'will'}], [{65: 'that', 67: 'that'}, {65: 'll', 67: 'will'}], [{65: 'that', 67: 'that'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'that', 67: 'that'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'that', 67: 'that'}, {65: \"'re\", 67: 'are'}], [{65: 'that', 67: 'that'}, {65: 're', 67: 'are'}], [{65: 'that', 67: 'that'}, {65: \"'ve\"}], [{65: 'that'}, {65: 've', 67: 'have'}], [{65: 'that', 67: 'that'}, {65: \"'d\", 67: \"'d\"}], [{65: 'that', 67: 'that'}, {65: 'd', 67: \"'d\"}], [{65: 'that', 67: 'that'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'that', 67: 'that'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'That', 67: 'that'}, {65: \"'s\", 67: \"'s\"}], [{65: 'That', 67: 'that'}, {65: 's'}], [{65: 'That', 67: 'that'}, {65: \"'ll\", 67: 'will'}], [{65: 'That', 67: 'that'}, {65: 'll', 67: 'will'}], [{65: 'That', 67: 'that'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'That', 67: 'that'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'That', 67: 'that'}, {65: \"'re\", 67: 'are'}], [{65: 'That', 67: 'that'}, {65: 're', 67: 'are'}], [{65: 'That', 67: 'that'}, {65: \"'ve\"}], [{65: 'That'}, {65: 've', 67: 'have'}], [{65: 'That', 67: 'that'}, {65: \"'d\", 67: \"'d\"}], [{65: 'That', 67: 'that'}, {65: 'd', 67: \"'d\"}], [{65: 'That', 67: 'that'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'That', 67: 'that'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'this', 67: 'this'}, {65: \"'s\", 67: \"'s\"}], [{65: 'this', 67: 'this'}, {65: 's'}], [{65: 'this', 67: 'this'}, {65: \"'ll\", 67: 'will'}], [{65: 'this', 67: 'this'}, {65: 'll', 67: 'will'}], [{65: 'this', 67: 'this'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'this', 67: 'this'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'this', 67: 'this'}, {65: \"'re\", 67: 'are'}], [{65: 'this', 67: 'this'}, {65: 're', 67: 'are'}], [{65: 'this', 67: 'this'}, {65: \"'ve\"}], [{65: 'this'}, {65: 've', 67: 'have'}], [{65: 'this', 67: 'this'}, {65: \"'d\", 67: \"'d\"}], [{65: 'this', 67: 'this'}, {65: 'd', 67: \"'d\"}], [{65: 'this', 67: 'this'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'this', 67: 'this'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'This', 67: 'this'}, {65: \"'s\", 67: \"'s\"}], [{65: 'This', 67: 'this'}, {65: 's'}], [{65: 'This', 67: 'this'}, {65: \"'ll\", 67: 'will'}], [{65: 'This', 67: 'this'}, {65: 'll', 67: 'will'}], [{65: 'This', 67: 'this'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'This', 67: 'this'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'This', 67: 'this'}, {65: \"'re\", 67: 'are'}], [{65: 'This', 67: 'this'}, {65: 're', 67: 'are'}], [{65: 'This', 67: 'this'}, {65: \"'ve\"}], [{65: 'This'}, {65: 've', 67: 'have'}], [{65: 'This', 67: 'this'}, {65: \"'d\", 67: \"'d\"}], [{65: 'This', 67: 'this'}, {65: 'd', 67: \"'d\"}], [{65: 'This', 67: 'this'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'This', 67: 'this'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'these', 67: 'these'}, {65: \"'s\", 67: \"'s\"}], [{65: 'these', 67: 'these'}, {65: 's'}], [{65: 'these', 67: 'these'}, {65: \"'ll\", 67: 'will'}], [{65: 'these', 67: 'these'}, {65: 'll', 67: 'will'}], [{65: 'these', 67: 'these'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'these', 67: 'these'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'these', 67: 'these'}, {65: \"'re\", 67: 'are'}], [{65: 'these', 67: 'these'}, {65: 're', 67: 'are'}], [{65: 'these', 67: 'these'}, {65: \"'ve\"}], [{65: 'these'}, {65: 've', 67: 'have'}], [{65: 'these', 67: 'these'}, {65: \"'d\", 67: \"'d\"}], [{65: 'these', 67: 'these'}, {65: 'd', 67: \"'d\"}], [{65: 'these', 67: 'these'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'these', 67: 'these'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'These', 67: 'these'}, {65: \"'s\", 67: \"'s\"}], [{65: 'These', 67: 'these'}, {65: 's'}], [{65: 'These', 67: 'these'}, {65: \"'ll\", 67: 'will'}], [{65: 'These', 67: 'these'}, {65: 'll', 67: 'will'}], [{65: 'These', 67: 'these'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'These', 67: 'these'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'These', 67: 'these'}, {65: \"'re\", 67: 'are'}], [{65: 'These', 67: 'these'}, {65: 're', 67: 'are'}], [{65: 'These', 67: 'these'}, {65: \"'ve\"}], [{65: 'These'}, {65: 've', 67: 'have'}], [{65: 'These', 67: 'these'}, {65: \"'d\", 67: \"'d\"}], [{65: 'These', 67: 'these'}, {65: 'd', 67: \"'d\"}], [{65: 'These', 67: 'these'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'These', 67: 'these'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'those', 67: 'those'}, {65: \"'s\", 67: \"'s\"}], [{65: 'those', 67: 'those'}, {65: 's'}], [{65: 'those', 67: 'those'}, {65: \"'ll\", 67: 'will'}], [{65: 'those', 67: 'those'}, {65: 'll', 67: 'will'}], [{65: 'those', 67: 'those'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'those', 67: 'those'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'those', 67: 'those'}, {65: \"'re\", 67: 'are'}], [{65: 'those', 67: 'those'}, {65: 're', 67: 'are'}], [{65: 'those', 67: 'those'}, {65: \"'ve\"}], [{65: 'those'}, {65: 've', 67: 'have'}], [{65: 'those', 67: 'those'}, {65: \"'d\", 67: \"'d\"}], [{65: 'those', 67: 'those'}, {65: 'd', 67: \"'d\"}], [{65: 'those', 67: 'those'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'those', 67: 'those'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'Those', 67: 'those'}, {65: \"'s\", 67: \"'s\"}], [{65: 'Those', 67: 'those'}, {65: 's'}], [{65: 'Those', 67: 'those'}, {65: \"'ll\", 67: 'will'}], [{65: 'Those', 67: 'those'}, {65: 'll', 67: 'will'}], [{65: 'Those', 67: 'those'}, {65: \"'ll\", 67: 'will'}, {65: \"'ve\", 67: 'have'}], [{65: 'Those', 67: 'those'}, {65: 'll', 67: 'will'}, {65: 've', 67: 'have'}], [{65: 'Those', 67: 'those'}, {65: \"'re\", 67: 'are'}], [{65: 'Those', 67: 'those'}, {65: 're', 67: 'are'}], [{65: 'Those', 67: 'those'}, {65: \"'ve\"}], [{65: 'Those'}, {65: 've', 67: 'have'}], [{65: 'Those', 67: 'those'}, {65: \"'d\", 67: \"'d\"}], [{65: 'Those', 67: 'those'}, {65: 'd', 67: \"'d\"}], [{65: 'Those', 67: 'those'}, {65: \"'d\", 67: 'would'}, {65: \"'ve\", 67: 'have'}], [{65: 'Those', 67: 'those'}, {65: 'd', 67: 'would'}, {65: 've', 67: 'have'}], [{65: 'ca', 67: 'can'}, {65: \"n't\", 67: 'not'}], [{65: 'ca', 67: 'can'}, {65: 'nt', 67: 'not'}], [{65: 'ca', 67: 'can'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'ca', 67: 'can'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Ca', 67: 'can'}, {65: \"n't\", 67: 'not'}], [{65: 'Ca', 67: 'can'}, {65: 'nt', 67: 'not'}], [{65: 'Ca', 67: 'can'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Ca', 67: 'can'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'could', 67: 'could'}, {65: \"n't\", 67: 'not'}], [{65: 'could', 67: 'could'}, {65: 'nt', 67: 'not'}], [{65: 'could', 67: 'could'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'could', 67: 'could'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Could', 67: 'could'}, {65: \"n't\", 67: 'not'}], [{65: 'Could', 67: 'could'}, {65: 'nt', 67: 'not'}], [{65: 'Could', 67: 'could'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Could', 67: 'could'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'do', 67: 'do'}, {65: \"n't\", 67: 'not'}], [{65: 'do', 67: 'do'}, {65: 'nt', 67: 'not'}], [{65: 'do', 67: 'do'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'do', 67: 'do'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Do', 67: 'do'}, {65: \"n't\", 67: 'not'}], [{65: 'Do', 67: 'do'}, {65: 'nt', 67: 'not'}], [{65: 'Do', 67: 'do'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Do', 67: 'do'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'does', 67: 'does'}, {65: \"n't\", 67: 'not'}], [{65: 'does', 67: 'does'}, {65: 'nt', 67: 'not'}], [{65: 'does', 67: 'does'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'does', 67: 'does'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Does', 67: 'does'}, {65: \"n't\", 67: 'not'}], [{65: 'Does', 67: 'does'}, {65: 'nt', 67: 'not'}], [{65: 'Does', 67: 'does'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Does', 67: 'does'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'did', 67: 'do'}, {65: \"n't\", 67: 'not'}], [{65: 'did', 67: 'do'}, {65: 'nt', 67: 'not'}], [{65: 'did', 67: 'do'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'did', 67: 'do'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Did', 67: 'do'}, {65: \"n't\", 67: 'not'}], [{65: 'Did', 67: 'do'}, {65: 'nt', 67: 'not'}], [{65: 'Did', 67: 'do'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Did', 67: 'do'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'had', 67: 'have'}, {65: \"n't\", 67: 'not'}], [{65: 'had', 67: 'have'}, {65: 'nt', 67: 'not'}], [{65: 'had', 67: 'have'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'had', 67: 'have'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Had', 67: 'have'}, {65: \"n't\", 67: 'not'}], [{65: 'Had', 67: 'have'}, {65: 'nt', 67: 'not'}], [{65: 'Had', 67: 'have'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Had', 67: 'have'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'may', 67: 'may'}, {65: \"n't\", 67: 'not'}], [{65: 'may', 67: 'may'}, {65: 'nt', 67: 'not'}], [{65: 'may', 67: 'may'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'may', 67: 'may'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'May', 67: 'may'}, {65: \"n't\", 67: 'not'}], [{65: 'May', 67: 'may'}, {65: 'nt', 67: 'not'}], [{65: 'May', 67: 'may'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'May', 67: 'may'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'might', 67: 'might'}, {65: \"n't\", 67: 'not'}], [{65: 'might', 67: 'might'}, {65: 'nt', 67: 'not'}], [{65: 'might', 67: 'might'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'might', 67: 'might'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Might', 67: 'might'}, {65: \"n't\", 67: 'not'}], [{65: 'Might', 67: 'might'}, {65: 'nt', 67: 'not'}], [{65: 'Might', 67: 'might'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Might', 67: 'might'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'must', 67: 'must'}, {65: \"n't\", 67: 'not'}], [{65: 'must', 67: 'must'}, {65: 'nt', 67: 'not'}], [{65: 'must', 67: 'must'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'must', 67: 'must'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Must', 67: 'must'}, {65: \"n't\", 67: 'not'}], [{65: 'Must', 67: 'must'}, {65: 'nt', 67: 'not'}], [{65: 'Must', 67: 'must'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Must', 67: 'must'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'need', 67: 'need'}, {65: \"n't\", 67: 'not'}], [{65: 'need', 67: 'need'}, {65: 'nt', 67: 'not'}], [{65: 'need', 67: 'need'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'need', 67: 'need'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Need', 67: 'need'}, {65: \"n't\", 67: 'not'}], [{65: 'Need', 67: 'need'}, {65: 'nt', 67: 'not'}], [{65: 'Need', 67: 'need'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Need', 67: 'need'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'ought', 67: 'ought'}, {65: \"n't\", 67: 'not'}], [{65: 'ought', 67: 'ought'}, {65: 'nt', 67: 'not'}], [{65: 'ought', 67: 'ought'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'ought', 67: 'ought'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Ought', 67: 'ought'}, {65: \"n't\", 67: 'not'}], [{65: 'Ought', 67: 'ought'}, {65: 'nt', 67: 'not'}], [{65: 'Ought', 67: 'ought'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Ought', 67: 'ought'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'sha', 67: 'shall'}, {65: \"n't\", 67: 'not'}], [{65: 'sha', 67: 'shall'}, {65: 'nt', 67: 'not'}], [{65: 'sha', 67: 'shall'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'sha', 67: 'shall'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Sha', 67: 'shall'}, {65: \"n't\", 67: 'not'}], [{65: 'Sha', 67: 'shall'}, {65: 'nt', 67: 'not'}], [{65: 'Sha', 67: 'shall'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Sha', 67: 'shall'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'should', 67: 'should'}, {65: \"n't\", 67: 'not'}], [{65: 'should', 67: 'should'}, {65: 'nt', 67: 'not'}], [{65: 'should', 67: 'should'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'should', 67: 'should'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Should', 67: 'should'}, {65: \"n't\", 67: 'not'}], [{65: 'Should', 67: 'should'}, {65: 'nt', 67: 'not'}], [{65: 'Should', 67: 'should'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Should', 67: 'should'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'wo', 67: 'will'}, {65: \"n't\", 67: 'not'}], [{65: 'wo', 67: 'will'}, {65: 'nt', 67: 'not'}], [{65: 'wo', 67: 'will'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'wo', 67: 'will'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Wo', 67: 'will'}, {65: \"n't\", 67: 'not'}], [{65: 'Wo', 67: 'will'}, {65: 'nt', 67: 'not'}], [{65: 'Wo', 67: 'will'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Wo', 67: 'will'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'would', 67: 'would'}, {65: \"n't\", 67: 'not'}], [{65: 'would', 67: 'would'}, {65: 'nt', 67: 'not'}], [{65: 'would', 67: 'would'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'would', 67: 'would'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'Would', 67: 'would'}, {65: \"n't\", 67: 'not'}], [{65: 'Would', 67: 'would'}, {65: 'nt', 67: 'not'}], [{65: 'Would', 67: 'would'}, {65: \"n't\", 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Would', 67: 'would'}, {65: 'nt', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'could', 67: 'could'}, {65: \"'ve\"}], [{65: 'could', 67: 'could'}, {65: 've'}], [{65: 'Could', 67: 'could'}, {65: \"'ve\"}], [{65: 'Could', 67: 'could'}, {65: 've'}], [{65: 'might', 67: 'might'}, {65: \"'ve\"}], [{65: 'might', 67: 'might'}, {65: 've'}], [{65: 'Might', 67: 'might'}, {65: \"'ve\"}], [{65: 'Might', 67: 'might'}, {65: 've'}], [{65: 'must', 67: 'must'}, {65: \"'ve\"}], [{65: 'must', 67: 'must'}, {65: 've'}], [{65: 'Must', 67: 'must'}, {65: \"'ve\"}], [{65: 'Must', 67: 'must'}, {65: 've'}], [{65: 'should', 67: 'should'}, {65: \"'ve\"}], [{65: 'should', 67: 'should'}, {65: 've'}], [{65: 'Should', 67: 'should'}, {65: \"'ve\"}], [{65: 'Should', 67: 'should'}, {65: 've'}], [{65: 'would', 67: 'would'}, {65: \"'ve\"}], [{65: 'would', 67: 'would'}, {65: 've'}], [{65: 'Would', 67: 'would'}, {65: \"'ve\"}], [{65: 'Would', 67: 'would'}, {65: 've'}], [{65: 'ai'}, {65: \"n't\", 67: 'not'}], [{65: 'ai'}, {65: 'nt', 67: 'not'}], [{65: 'Ai'}, {65: \"n't\", 67: 'not'}], [{65: 'Ai'}, {65: 'nt', 67: 'not'}], [{65: 'are', 67: 'are'}, {65: \"n't\", 67: 'not'}], [{65: 'are', 67: 'are'}, {65: 'nt', 67: 'not'}], [{65: 'Are', 67: 'are'}, {65: \"n't\", 67: 'not'}], [{65: 'Are', 67: 'are'}, {65: 'nt', 67: 'not'}], [{65: 'is', 67: 'is'}, {65: \"n't\", 67: 'not'}], [{65: 'is', 67: 'is'}, {65: 'nt', 67: 'not'}], [{65: 'Is', 67: 'is'}, {65: \"n't\", 67: 'not'}], [{65: 'Is', 67: 'is'}, {65: 'nt', 67: 'not'}], [{65: 'was', 67: 'was'}, {65: \"n't\", 67: 'not'}], [{65: 'was', 67: 'was'}, {65: 'nt', 67: 'not'}], [{65: 'Was', 67: 'was'}, {65: \"n't\", 67: 'not'}], [{65: 'Was', 67: 'was'}, {65: 'nt', 67: 'not'}], [{65: 'were', 67: 'were'}, {65: \"n't\", 67: 'not'}], [{65: 'were', 67: 'were'}, {65: 'nt', 67: 'not'}], [{65: 'Were', 67: 'were'}, {65: \"n't\", 67: 'not'}], [{65: 'Were', 67: 'were'}, {65: 'nt', 67: 'not'}], [{65: 'have', 67: 'have'}, {65: \"n't\", 67: 'not'}], [{65: 'have', 67: 'have'}, {65: 'nt', 67: 'not'}], [{65: 'Have', 67: 'have'}, {65: \"n't\", 67: 'not'}], [{65: 'Have', 67: 'have'}, {65: 'nt', 67: 'not'}], [{65: 'has', 67: 'has'}, {65: \"n't\", 67: 'not'}], [{65: 'has', 67: 'has'}, {65: 'nt', 67: 'not'}], [{65: 'Has', 67: 'has'}, {65: \"n't\", 67: 'not'}], [{65: 'Has', 67: 'has'}, {65: 'nt', 67: 'not'}], [{65: 'dare', 67: 'dare'}, {65: \"n't\", 67: 'not'}], [{65: 'dare', 67: 'dare'}, {65: 'nt', 67: 'not'}], [{65: 'Dare', 67: 'dare'}, {65: \"n't\", 67: 'not'}], [{65: 'Dare', 67: 'dare'}, {65: 'nt', 67: 'not'}], [{65: 'doin', 67: 'doing'}], [{65: \"doin'\", 67: 'doing'}], [{65: 'Doin', 67: 'doing'}], [{65: \"Doin'\", 67: 'doing'}], [{65: 'goin', 67: 'going'}], [{65: \"goin'\", 67: 'going'}], [{65: 'Goin', 67: 'going'}], [{65: \"Goin'\", 67: 'going'}], [{65: 'nothin', 67: 'nothing'}], [{65: \"nothin'\", 67: 'nothing'}], [{65: 'Nothin', 67: 'nothing'}], [{65: \"Nothin'\", 67: 'nothing'}], [{65: 'nuthin', 67: 'nothing'}], [{65: \"nuthin'\", 67: 'nothing'}], [{65: 'Nuthin', 67: 'nothing'}], [{65: \"Nuthin'\", 67: 'nothing'}], [{65: 'ol', 67: 'old'}], [{65: \"ol'\", 67: 'old'}], [{65: 'Ol', 67: 'old'}], [{65: \"Ol'\", 67: 'old'}], [{65: 'somethin', 67: 'something'}], [{65: \"somethin'\", 67: 'something'}], [{65: 'Somethin', 67: 'something'}], [{65: \"Somethin'\", 67: 'something'}], [{65: 'em', 67: 'them'}], [{65: \"'em\", 67: 'them'}], [{65: 'll', 67: 'will'}], [{65: \"'ll\", 67: 'will'}], [{65: 'nuff', 67: 'enough'}], [{65: \"'nuff\", 67: 'enough'}], [{65: '1'}, {65: 'a.m.', 67: 'a.m.'}], [{65: '1'}, {65: 'am', 67: 'a.m.'}], [{65: '1'}, {65: 'p.m.', 67: 'p.m.'}], [{65: '1'}, {65: 'pm', 67: 'p.m.'}], [{65: '2'}, {65: 'a.m.', 67: 'a.m.'}], [{65: '2'}, {65: 'am', 67: 'a.m.'}], [{65: '2'}, {65: 'p.m.', 67: 'p.m.'}], [{65: '2'}, {65: 'pm', 67: 'p.m.'}], [{65: '3'}, {65: 'a.m.', 67: 'a.m.'}], [{65: '3'}, {65: 'am', 67: 'a.m.'}], [{65: '3'}, {65: 'p.m.', 67: 'p.m.'}], [{65: '3'}, {65: 'pm', 67: 'p.m.'}], [{65: '4'}, {65: 'a.m.', 67: 'a.m.'}], [{65: '4'}, {65: 'am', 67: 'a.m.'}], [{65: '4'}, {65: 'p.m.', 67: 'p.m.'}], [{65: '4'}, {65: 'pm', 67: 'p.m.'}], [{65: '5'}, {65: 'a.m.', 67: 'a.m.'}], [{65: '5'}, {65: 'am', 67: 'a.m.'}], [{65: '5'}, {65: 'p.m.', 67: 'p.m.'}], [{65: '5'}, {65: 'pm', 67: 'p.m.'}], [{65: '6'}, {65: 'a.m.', 67: 'a.m.'}], [{65: '6'}, {65: 'am', 67: 'a.m.'}], [{65: '6'}, {65: 'p.m.', 67: 'p.m.'}], [{65: '6'}, {65: 'pm', 67: 'p.m.'}], [{65: '7'}, {65: 'a.m.', 67: 'a.m.'}], [{65: '7'}, {65: 'am', 67: 'a.m.'}], [{65: '7'}, {65: 'p.m.', 67: 'p.m.'}], [{65: '7'}, {65: 'pm', 67: 'p.m.'}], [{65: '8'}, {65: 'a.m.', 67: 'a.m.'}], [{65: '8'}, {65: 'am', 67: 'a.m.'}], [{65: '8'}, {65: 'p.m.', 67: 'p.m.'}], [{65: '8'}, {65: 'pm', 67: 'p.m.'}], [{65: '9'}, {65: 'a.m.', 67: 'a.m.'}], [{65: '9'}, {65: 'am', 67: 'a.m.'}], [{65: '9'}, {65: 'p.m.', 67: 'p.m.'}], [{65: '9'}, {65: 'pm', 67: 'p.m.'}], [{65: '10'}, {65: 'a.m.', 67: 'a.m.'}], [{65: '10'}, {65: 'am', 67: 'a.m.'}], [{65: '10'}, {65: 'p.m.', 67: 'p.m.'}], [{65: '10'}, {65: 'pm', 67: 'p.m.'}], [{65: '11'}, {65: 'a.m.', 67: 'a.m.'}], [{65: '11'}, {65: 'am', 67: 'a.m.'}], [{65: '11'}, {65: 'p.m.', 67: 'p.m.'}], [{65: '11'}, {65: 'pm', 67: 'p.m.'}], [{65: '12'}, {65: 'a.m.', 67: 'a.m.'}], [{65: '12'}, {65: 'am', 67: 'a.m.'}], [{65: '12'}, {65: 'p.m.', 67: 'p.m.'}], [{65: '12'}, {65: 'pm', 67: 'p.m.'}], [{65: \"y'\", 67: 'you'}, {65: 'all'}], [{65: 'y', 67: 'you'}, {65: 'all'}], [{65: 'how'}, {65: \"'d\"}, {65: \"'y\", 67: 'you'}], [{65: 'How', 67: 'how'}, {65: \"'d\"}, {65: \"'y\", 67: 'you'}], [{65: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'not'}, {65: 've', 67: 'have'}], [{65: 'Not', 67: 'not'}, {65: \"'ve\", 67: 'have'}], [{65: 'Not', 67: 'not'}, {65: 've', 67: 'have'}], [{65: 'can'}, {65: 'not'}], [{65: 'Can', 67: 'can'}, {65: 'not'}], [{65: 'gon', 67: 'going'}, {65: 'na', 67: 'to'}], [{65: 'Gon', 67: 'going'}, {65: 'na', 67: 'to'}], [{65: 'got'}, {65: 'ta', 67: 'to'}], [{65: 'Got', 67: 'got'}, {65: 'ta', 67: 'to'}], [{65: 'let'}, {65: \"'s\", 67: 'us'}], [{65: 'Let', 67: 'let'}, {65: \"'s\", 67: 'us'}], [{65: \"c'm\", 67: 'come'}, {65: 'on'}], [{65: \"C'm\", 67: 'come'}, {65: 'on'}], [{65: \"'S\", 67: \"'s\"}], [{65: \"'s\", 67: \"'s\"}], [{65: '‘S', 67: \"'s\"}], [{65: '‘s', 67: \"'s\"}], [{65: 'and/or', 67: 'and/or'}], [{65: 'w/o', 67: 'without'}], [{65: \"'re\", 67: 'are'}], [{65: \"'Cause\", 67: 'because'}], [{65: \"'cause\", 67: 'because'}], [{65: \"'cos\", 67: 'because'}], [{65: \"'Cos\", 67: 'because'}], [{65: \"'coz\", 67: 'because'}], [{65: \"'Coz\", 67: 'because'}], [{65: \"'cuz\", 67: 'because'}], [{65: \"'Cuz\", 67: 'because'}], [{65: \"'bout\", 67: 'about'}], [{65: \"ma'am\", 67: 'madam'}], [{65: \"Ma'am\", 67: 'madam'}], [{65: \"o'clock\", 67: \"o'clock\"}], [{65: \"O'clock\", 67: \"o'clock\"}], [{65: \"lovin'\", 67: 'loving'}], [{65: \"Lovin'\", 67: 'loving'}], [{65: 'lovin', 67: 'loving'}], [{65: 'Lovin', 67: 'loving'}], [{65: \"havin'\", 67: 'having'}], [{65: \"Havin'\", 67: 'having'}], [{65: 'havin', 67: 'having'}], [{65: 'Havin', 67: 'having'}], [{65: 'Mt.', 67: 'Mount'}], [{65: 'Ak.', 67: 'Alaska'}], [{65: 'Ala.', 67: 'Alabama'}], [{65: 'Apr.', 67: 'April'}], [{65: 'Ariz.', 67: 'Arizona'}], [{65: 'Ark.', 67: 'Arkansas'}], [{65: 'Aug.', 67: 'August'}], [{65: 'Calif.', 67: 'California'}], [{65: 'Colo.', 67: 'Colorado'}], [{65: 'Conn.', 67: 'Connecticut'}], [{65: 'Dec.', 67: 'December'}], [{65: 'Del.', 67: 'Delaware'}], [{65: 'Feb.', 67: 'February'}], [{65: 'Fla.', 67: 'Florida'}], [{65: 'Ga.', 67: 'Georgia'}], [{65: 'Ia.', 67: 'Iowa'}], [{65: 'Id.', 67: 'Idaho'}], [{65: 'Ill.', 67: 'Illinois'}], [{65: 'Ind.', 67: 'Indiana'}], [{65: 'Jan.', 67: 'January'}], [{65: 'Jul.', 67: 'July'}], [{65: 'Jun.', 67: 'June'}], [{65: 'Kan.', 67: 'Kansas'}], [{65: 'Kans.', 67: 'Kansas'}], [{65: 'Ky.', 67: 'Kentucky'}], [{65: 'La.', 67: 'Louisiana'}], [{65: 'Mar.', 67: 'March'}], [{65: 'Mass.', 67: 'Massachusetts'}], [{65: 'May.', 67: 'May'}], [{65: 'Mich.', 67: 'Michigan'}], [{65: 'Minn.', 67: 'Minnesota'}], [{65: 'Miss.', 67: 'Mississippi'}], [{65: 'N.C.', 67: 'North Carolina'}], [{65: 'N.D.', 67: 'North Dakota'}], [{65: 'N.H.', 67: 'New Hampshire'}], [{65: 'N.J.', 67: 'New Jersey'}], [{65: 'N.M.', 67: 'New Mexico'}], [{65: 'N.Y.', 67: 'New York'}], [{65: 'Neb.', 67: 'Nebraska'}], [{65: 'Nebr.', 67: 'Nebraska'}], [{65: 'Nev.', 67: 'Nevada'}], [{65: 'Nov.', 67: 'November'}], [{65: 'Oct.', 67: 'October'}], [{65: 'Okla.', 67: 'Oklahoma'}], [{65: 'Ore.', 67: 'Oregon'}], [{65: 'Pa.', 67: 'Pennsylvania'}], [{65: 'S.C.', 67: 'South Carolina'}], [{65: 'Sep.', 67: 'September'}], [{65: 'Sept.', 67: 'September'}], [{65: 'Tenn.', 67: 'Tennessee'}], [{65: 'Va.', 67: 'Virginia'}], [{65: 'Wash.', 67: 'Washington'}], [{65: 'Wis.', 67: 'Wisconsin'}], [{65: \"'d\"}], [{65: 'a.m.'}], [{65: 'Adm.'}], [{65: 'Bros.'}], [{65: 'co.'}], [{65: 'Co.'}], [{65: 'Corp.'}], [{65: 'D.C.'}], [{65: 'Dr.'}], [{65: 'e.g.'}], [{65: 'E.g.'}], [{65: 'E.G.'}], [{65: 'Gen.'}], [{65: 'Gov.'}], [{65: 'i.e.'}], [{65: 'I.e.'}], [{65: 'I.E.'}], [{65: 'Inc.'}], [{65: 'Jr.'}], [{65: 'Ltd.'}], [{65: 'Md.'}], [{65: 'Messrs.'}], [{65: 'Mo.'}], [{65: 'Mont.'}], [{65: 'Mr.'}], [{65: 'Mrs.'}], [{65: 'Ms.'}], [{65: 'p.m.'}], [{65: 'Ph.D.'}], [{65: 'Prof.'}], [{65: 'Rep.'}], [{65: 'Rev.'}], [{65: 'Sen.'}], [{65: 'St.'}], [{65: 'vs.'}], [{65: 'v.s.'}], [{65: '’'}], [{65: '’’'}], [{65: ':’)'}], [{65: ':’-('}], [{65: ':’-)'}], [{65: ':’('}], [{65: 'i', 67: 'i'}, {65: '’m', 67: 'am'}], [{65: 'i', 67: 'i'}, {65: '’m', 67: 'am'}, {65: 'a', 67: 'gonna'}], [{65: 'I', 67: 'i'}, {65: '’m', 67: 'am'}], [{65: 'I', 67: 'i'}, {65: '’m', 67: 'am'}, {65: 'a', 67: 'gonna'}], [{65: 'i', 67: 'i'}, {65: '’ll', 67: 'will'}], [{65: 'i', 67: 'i'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'i', 67: 'i'}, {65: '’d', 67: \"'d\"}], [{65: 'i', 67: 'i'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'I', 67: 'i'}, {65: '’ll', 67: 'will'}], [{65: 'I', 67: 'i'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'I', 67: 'i'}, {65: '’d', 67: \"'d\"}], [{65: 'I', 67: 'i'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'you', 67: 'you'}, {65: '’ll', 67: 'will'}], [{65: 'you', 67: 'you'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'you', 67: 'you'}, {65: '’d', 67: \"'d\"}], [{65: 'you', 67: 'you'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'You', 67: 'you'}, {65: '’ll', 67: 'will'}], [{65: 'You', 67: 'you'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'You', 67: 'you'}, {65: '’d', 67: \"'d\"}], [{65: 'You', 67: 'you'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'he', 67: 'he'}, {65: '’ll', 67: 'will'}], [{65: 'he', 67: 'he'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'he', 67: 'he'}, {65: '’d', 67: \"'d\"}], [{65: 'he', 67: 'he'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'He', 67: 'he'}, {65: '’ll', 67: 'will'}], [{65: 'He', 67: 'he'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'He', 67: 'he'}, {65: '’d', 67: \"'d\"}], [{65: 'He', 67: 'he'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'she', 67: 'she'}, {65: '’ll', 67: 'will'}], [{65: 'she', 67: 'she'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'she', 67: 'she'}, {65: '’d', 67: \"'d\"}], [{65: 'she', 67: 'she'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'She', 67: 'she'}, {65: '’ll', 67: 'will'}], [{65: 'She', 67: 'she'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'She', 67: 'she'}, {65: '’d', 67: \"'d\"}], [{65: 'She', 67: 'she'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'it', 67: 'it'}, {65: '’ll', 67: 'will'}], [{65: 'it', 67: 'it'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'it', 67: 'it'}, {65: '’d', 67: \"'d\"}], [{65: 'it', 67: 'it'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'It', 67: 'it'}, {65: '’ll', 67: 'will'}], [{65: 'It', 67: 'it'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'It', 67: 'it'}, {65: '’d', 67: \"'d\"}], [{65: 'It', 67: 'it'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'we', 67: 'we'}, {65: '’ll', 67: 'will'}], [{65: 'we', 67: 'we'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'we', 67: 'we'}, {65: '’d', 67: \"'d\"}], [{65: 'we', 67: 'we'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'We', 67: 'we'}, {65: '’ll', 67: 'will'}], [{65: 'We', 67: 'we'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'We', 67: 'we'}, {65: '’d', 67: \"'d\"}], [{65: 'We', 67: 'we'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'they', 67: 'they'}, {65: '’ll', 67: 'will'}], [{65: 'they', 67: 'they'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'they', 67: 'they'}, {65: '’d', 67: \"'d\"}], [{65: 'they', 67: 'they'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'They', 67: 'they'}, {65: '’ll', 67: 'will'}], [{65: 'They', 67: 'they'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'They', 67: 'they'}, {65: '’d', 67: \"'d\"}], [{65: 'They', 67: 'they'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'i', 67: 'i'}, {65: '’ve', 67: 'have'}], [{65: 'I', 67: 'i'}, {65: '’ve', 67: 'have'}], [{65: 'you', 67: 'you'}, {65: '’ve', 67: 'have'}], [{65: 'You', 67: 'you'}, {65: '’ve', 67: 'have'}], [{65: 'we', 67: 'we'}, {65: '’ve', 67: 'have'}], [{65: 'We', 67: 'we'}, {65: '’ve', 67: 'have'}], [{65: 'they', 67: 'they'}, {65: '’ve', 67: 'have'}], [{65: 'They', 67: 'they'}, {65: '’ve', 67: 'have'}], [{65: 'you', 67: 'you'}, {65: '’re', 67: 'are'}], [{65: 'You', 67: 'you'}, {65: '’re', 67: 'are'}], [{65: 'we', 67: 'we'}, {65: '’re', 67: 'are'}], [{65: 'We', 67: 'we'}, {65: '’re', 67: 'are'}], [{65: 'they', 67: 'they'}, {65: '’re', 67: 'are'}], [{65: 'They', 67: 'they'}, {65: '’re', 67: 'are'}], [{65: 'he', 67: 'he'}, {65: '’s', 67: \"'s\"}], [{65: 'He', 67: 'he'}, {65: '’s', 67: \"'s\"}], [{65: 'she', 67: 'she'}, {65: '’s', 67: \"'s\"}], [{65: 'She', 67: 'she'}, {65: '’s', 67: \"'s\"}], [{65: 'it', 67: 'it'}, {65: '’s', 67: \"'s\"}], [{65: 'It', 67: 'it'}, {65: '’s', 67: \"'s\"}], [{65: 'who', 67: 'who'}, {65: '’s', 67: \"'s\"}], [{65: 'who', 67: 'who'}, {65: '’ll', 67: 'will'}], [{65: 'who', 67: 'who'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'who', 67: 'who'}, {65: '’re', 67: 'are'}], [{65: 'who', 67: 'who'}, {65: '’ve'}], [{65: 'who', 67: 'who'}, {65: '’d', 67: \"'d\"}], [{65: 'who', 67: 'who'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'Who', 67: 'who'}, {65: '’s', 67: \"'s\"}], [{65: 'Who', 67: 'who'}, {65: '’ll', 67: 'will'}], [{65: 'Who', 67: 'who'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'Who', 67: 'who'}, {65: '’re', 67: 'are'}], [{65: 'Who', 67: 'who'}, {65: '’ve'}], [{65: 'Who', 67: 'who'}, {65: '’d', 67: \"'d\"}], [{65: 'Who', 67: 'who'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'what', 67: 'what'}, {65: '’s', 67: \"'s\"}], [{65: 'what', 67: 'what'}, {65: '’ll', 67: 'will'}], [{65: 'what', 67: 'what'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'what', 67: 'what'}, {65: '’re', 67: 'are'}], [{65: 'what', 67: 'what'}, {65: '’ve'}], [{65: 'what', 67: 'what'}, {65: '’d', 67: \"'d\"}], [{65: 'what', 67: 'what'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'What', 67: 'what'}, {65: '’s', 67: \"'s\"}], [{65: 'What', 67: 'what'}, {65: '’ll', 67: 'will'}], [{65: 'What', 67: 'what'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'What', 67: 'what'}, {65: '’re', 67: 'are'}], [{65: 'What', 67: 'what'}, {65: '’ve'}], [{65: 'What', 67: 'what'}, {65: '’d', 67: \"'d\"}], [{65: 'What', 67: 'what'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'when', 67: 'when'}, {65: '’s', 67: \"'s\"}], [{65: 'when', 67: 'when'}, {65: '’ll', 67: 'will'}], [{65: 'when', 67: 'when'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'when', 67: 'when'}, {65: '’re', 67: 'are'}], [{65: 'when', 67: 'when'}, {65: '’ve'}], [{65: 'when', 67: 'when'}, {65: '’d', 67: \"'d\"}], [{65: 'when', 67: 'when'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'When', 67: 'when'}, {65: '’s', 67: \"'s\"}], [{65: 'When', 67: 'when'}, {65: '’ll', 67: 'will'}], [{65: 'When', 67: 'when'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'When', 67: 'when'}, {65: '’re', 67: 'are'}], [{65: 'When', 67: 'when'}, {65: '’ve'}], [{65: 'When', 67: 'when'}, {65: '’d', 67: \"'d\"}], [{65: 'When', 67: 'when'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'where', 67: 'where'}, {65: '’s', 67: \"'s\"}], [{65: 'where', 67: 'where'}, {65: '’ll', 67: 'will'}], [{65: 'where', 67: 'where'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'where', 67: 'where'}, {65: '’re', 67: 'are'}], [{65: 'where', 67: 'where'}, {65: '’ve'}], [{65: 'where', 67: 'where'}, {65: '’d', 67: \"'d\"}], [{65: 'where', 67: 'where'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'Where', 67: 'where'}, {65: '’s', 67: \"'s\"}], [{65: 'Where', 67: 'where'}, {65: '’ll', 67: 'will'}], [{65: 'Where', 67: 'where'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'Where', 67: 'where'}, {65: '’re', 67: 'are'}], [{65: 'Where', 67: 'where'}, {65: '’ve'}], [{65: 'Where', 67: 'where'}, {65: '’d', 67: \"'d\"}], [{65: 'Where', 67: 'where'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'why', 67: 'why'}, {65: '’s', 67: \"'s\"}], [{65: 'why', 67: 'why'}, {65: '’ll', 67: 'will'}], [{65: 'why', 67: 'why'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'why', 67: 'why'}, {65: '’re', 67: 'are'}], [{65: 'why', 67: 'why'}, {65: '’ve'}], [{65: 'why', 67: 'why'}, {65: '’d', 67: \"'d\"}], [{65: 'why', 67: 'why'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'Why', 67: 'why'}, {65: '’s', 67: \"'s\"}], [{65: 'Why', 67: 'why'}, {65: '’ll', 67: 'will'}], [{65: 'Why', 67: 'why'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'Why', 67: 'why'}, {65: '’re', 67: 'are'}], [{65: 'Why', 67: 'why'}, {65: '’ve'}], [{65: 'Why', 67: 'why'}, {65: '’d', 67: \"'d\"}], [{65: 'Why', 67: 'why'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'how', 67: 'how'}, {65: '’s', 67: \"'s\"}], [{65: 'how', 67: 'how'}, {65: '’ll', 67: 'will'}], [{65: 'how', 67: 'how'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'how', 67: 'how'}, {65: '’re', 67: 'are'}], [{65: 'how', 67: 'how'}, {65: '’ve'}], [{65: 'how', 67: 'how'}, {65: '’d', 67: \"'d\"}], [{65: 'how', 67: 'how'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'How', 67: 'how'}, {65: '’s', 67: \"'s\"}], [{65: 'How', 67: 'how'}, {65: '’ll', 67: 'will'}], [{65: 'How', 67: 'how'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'How', 67: 'how'}, {65: '’re', 67: 'are'}], [{65: 'How', 67: 'how'}, {65: '’ve'}], [{65: 'How', 67: 'how'}, {65: '’d', 67: \"'d\"}], [{65: 'How', 67: 'how'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'there', 67: 'there'}, {65: '’s', 67: \"'s\"}], [{65: 'there', 67: 'there'}, {65: '’ll', 67: 'will'}], [{65: 'there', 67: 'there'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'there', 67: 'there'}, {65: '’re', 67: 'are'}], [{65: 'there', 67: 'there'}, {65: '’ve'}], [{65: 'there', 67: 'there'}, {65: '’d', 67: \"'d\"}], [{65: 'there', 67: 'there'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'There', 67: 'there'}, {65: '’s', 67: \"'s\"}], [{65: 'There', 67: 'there'}, {65: '’ll', 67: 'will'}], [{65: 'There', 67: 'there'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'There', 67: 'there'}, {65: '’re', 67: 'are'}], [{65: 'There', 67: 'there'}, {65: '’ve'}], [{65: 'There', 67: 'there'}, {65: '’d', 67: \"'d\"}], [{65: 'There', 67: 'there'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'that', 67: 'that'}, {65: '’s', 67: \"'s\"}], [{65: 'that', 67: 'that'}, {65: '’ll', 67: 'will'}], [{65: 'that', 67: 'that'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'that', 67: 'that'}, {65: '’re', 67: 'are'}], [{65: 'that', 67: 'that'}, {65: '’ve'}], [{65: 'that', 67: 'that'}, {65: '’d', 67: \"'d\"}], [{65: 'that', 67: 'that'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'That', 67: 'that'}, {65: '’s', 67: \"'s\"}], [{65: 'That', 67: 'that'}, {65: '’ll', 67: 'will'}], [{65: 'That', 67: 'that'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'That', 67: 'that'}, {65: '’re', 67: 'are'}], [{65: 'That', 67: 'that'}, {65: '’ve'}], [{65: 'That', 67: 'that'}, {65: '’d', 67: \"'d\"}], [{65: 'That', 67: 'that'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'this', 67: 'this'}, {65: '’s', 67: \"'s\"}], [{65: 'this', 67: 'this'}, {65: '’ll', 67: 'will'}], [{65: 'this', 67: 'this'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'this', 67: 'this'}, {65: '’re', 67: 'are'}], [{65: 'this', 67: 'this'}, {65: '’ve'}], [{65: 'this', 67: 'this'}, {65: '’d', 67: \"'d\"}], [{65: 'this', 67: 'this'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'This', 67: 'this'}, {65: '’s', 67: \"'s\"}], [{65: 'This', 67: 'this'}, {65: '’ll', 67: 'will'}], [{65: 'This', 67: 'this'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'This', 67: 'this'}, {65: '’re', 67: 'are'}], [{65: 'This', 67: 'this'}, {65: '’ve'}], [{65: 'This', 67: 'this'}, {65: '’d', 67: \"'d\"}], [{65: 'This', 67: 'this'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'these', 67: 'these'}, {65: '’s', 67: \"'s\"}], [{65: 'these', 67: 'these'}, {65: '’ll', 67: 'will'}], [{65: 'these', 67: 'these'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'these', 67: 'these'}, {65: '’re', 67: 'are'}], [{65: 'these', 67: 'these'}, {65: '’ve'}], [{65: 'these', 67: 'these'}, {65: '’d', 67: \"'d\"}], [{65: 'these', 67: 'these'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'These', 67: 'these'}, {65: '’s', 67: \"'s\"}], [{65: 'These', 67: 'these'}, {65: '’ll', 67: 'will'}], [{65: 'These', 67: 'these'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'These', 67: 'these'}, {65: '’re', 67: 'are'}], [{65: 'These', 67: 'these'}, {65: '’ve'}], [{65: 'These', 67: 'these'}, {65: '’d', 67: \"'d\"}], [{65: 'These', 67: 'these'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'those', 67: 'those'}, {65: '’s', 67: \"'s\"}], [{65: 'those', 67: 'those'}, {65: '’ll', 67: 'will'}], [{65: 'those', 67: 'those'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'those', 67: 'those'}, {65: '’re', 67: 'are'}], [{65: 'those', 67: 'those'}, {65: '’ve'}], [{65: 'those', 67: 'those'}, {65: '’d', 67: \"'d\"}], [{65: 'those', 67: 'those'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'Those', 67: 'those'}, {65: '’s', 67: \"'s\"}], [{65: 'Those', 67: 'those'}, {65: '’ll', 67: 'will'}], [{65: 'Those', 67: 'those'}, {65: '’ll', 67: 'will'}, {65: '’ve', 67: 'have'}], [{65: 'Those', 67: 'those'}, {65: '’re', 67: 'are'}], [{65: 'Those', 67: 'those'}, {65: '’ve'}], [{65: 'Those', 67: 'those'}, {65: '’d', 67: \"'d\"}], [{65: 'Those', 67: 'those'}, {65: '’d', 67: 'would'}, {65: '’ve', 67: 'have'}], [{65: 'ca', 67: 'can'}, {65: 'n’t', 67: 'not'}], [{65: 'ca', 67: 'can'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Ca', 67: 'can'}, {65: 'n’t', 67: 'not'}], [{65: 'Ca', 67: 'can'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'could', 67: 'could'}, {65: 'n’t', 67: 'not'}], [{65: 'could', 67: 'could'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Could', 67: 'could'}, {65: 'n’t', 67: 'not'}], [{65: 'Could', 67: 'could'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'do', 67: 'do'}, {65: 'n’t', 67: 'not'}], [{65: 'do', 67: 'do'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Do', 67: 'do'}, {65: 'n’t', 67: 'not'}], [{65: 'Do', 67: 'do'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'does', 67: 'does'}, {65: 'n’t', 67: 'not'}], [{65: 'does', 67: 'does'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Does', 67: 'does'}, {65: 'n’t', 67: 'not'}], [{65: 'Does', 67: 'does'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'did', 67: 'do'}, {65: 'n’t', 67: 'not'}], [{65: 'did', 67: 'do'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Did', 67: 'do'}, {65: 'n’t', 67: 'not'}], [{65: 'Did', 67: 'do'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'had', 67: 'have'}, {65: 'n’t', 67: 'not'}], [{65: 'had', 67: 'have'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Had', 67: 'have'}, {65: 'n’t', 67: 'not'}], [{65: 'Had', 67: 'have'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'may', 67: 'may'}, {65: 'n’t', 67: 'not'}], [{65: 'may', 67: 'may'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'May', 67: 'may'}, {65: 'n’t', 67: 'not'}], [{65: 'May', 67: 'may'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'might', 67: 'might'}, {65: 'n’t', 67: 'not'}], [{65: 'might', 67: 'might'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Might', 67: 'might'}, {65: 'n’t', 67: 'not'}], [{65: 'Might', 67: 'might'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'must', 67: 'must'}, {65: 'n’t', 67: 'not'}], [{65: 'must', 67: 'must'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Must', 67: 'must'}, {65: 'n’t', 67: 'not'}], [{65: 'Must', 67: 'must'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'need', 67: 'need'}, {65: 'n’t', 67: 'not'}], [{65: 'need', 67: 'need'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Need', 67: 'need'}, {65: 'n’t', 67: 'not'}], [{65: 'Need', 67: 'need'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'ought', 67: 'ought'}, {65: 'n’t', 67: 'not'}], [{65: 'ought', 67: 'ought'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Ought', 67: 'ought'}, {65: 'n’t', 67: 'not'}], [{65: 'Ought', 67: 'ought'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'sha', 67: 'shall'}, {65: 'n’t', 67: 'not'}], [{65: 'sha', 67: 'shall'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Sha', 67: 'shall'}, {65: 'n’t', 67: 'not'}], [{65: 'Sha', 67: 'shall'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'should', 67: 'should'}, {65: 'n’t', 67: 'not'}], [{65: 'should', 67: 'should'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Should', 67: 'should'}, {65: 'n’t', 67: 'not'}], [{65: 'Should', 67: 'should'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'wo', 67: 'will'}, {65: 'n’t', 67: 'not'}], [{65: 'wo', 67: 'will'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Wo', 67: 'will'}, {65: 'n’t', 67: 'not'}], [{65: 'Wo', 67: 'will'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'would', 67: 'would'}, {65: 'n’t', 67: 'not'}], [{65: 'would', 67: 'would'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Would', 67: 'would'}, {65: 'n’t', 67: 'not'}], [{65: 'Would', 67: 'would'}, {65: 'n’t', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'could', 67: 'could'}, {65: '’ve'}], [{65: 'Could', 67: 'could'}, {65: '’ve'}], [{65: 'might', 67: 'might'}, {65: '’ve'}], [{65: 'Might', 67: 'might'}, {65: '’ve'}], [{65: 'must', 67: 'must'}, {65: '’ve'}], [{65: 'Must', 67: 'must'}, {65: '’ve'}], [{65: 'should', 67: 'should'}, {65: '’ve'}], [{65: 'Should', 67: 'should'}, {65: '’ve'}], [{65: 'would', 67: 'would'}, {65: '’ve'}], [{65: 'Would', 67: 'would'}, {65: '’ve'}], [{65: 'ai'}, {65: 'n’t', 67: 'not'}], [{65: 'Ai'}, {65: 'n’t', 67: 'not'}], [{65: 'are', 67: 'are'}, {65: 'n’t', 67: 'not'}], [{65: 'Are', 67: 'are'}, {65: 'n’t', 67: 'not'}], [{65: 'is', 67: 'is'}, {65: 'n’t', 67: 'not'}], [{65: 'Is', 67: 'is'}, {65: 'n’t', 67: 'not'}], [{65: 'was', 67: 'was'}, {65: 'n’t', 67: 'not'}], [{65: 'Was', 67: 'was'}, {65: 'n’t', 67: 'not'}], [{65: 'were', 67: 'were'}, {65: 'n’t', 67: 'not'}], [{65: 'Were', 67: 'were'}, {65: 'n’t', 67: 'not'}], [{65: 'have', 67: 'have'}, {65: 'n’t', 67: 'not'}], [{65: 'Have', 67: 'have'}, {65: 'n’t', 67: 'not'}], [{65: 'has', 67: 'has'}, {65: 'n’t', 67: 'not'}], [{65: 'Has', 67: 'has'}, {65: 'n’t', 67: 'not'}], [{65: 'dare', 67: 'dare'}, {65: 'n’t', 67: 'not'}], [{65: 'Dare', 67: 'dare'}, {65: 'n’t', 67: 'not'}], [{65: 'doin’', 67: 'doing'}], [{65: 'Doin’', 67: 'doing'}], [{65: 'goin’', 67: 'going'}], [{65: 'Goin’', 67: 'going'}], [{65: 'nothin’', 67: 'nothing'}], [{65: 'Nothin’', 67: 'nothing'}], [{65: 'nuthin’', 67: 'nothing'}], [{65: 'Nuthin’', 67: 'nothing'}], [{65: 'ol’', 67: 'old'}], [{65: 'Ol’', 67: 'old'}], [{65: 'somethin’', 67: 'something'}], [{65: 'Somethin’', 67: 'something'}], [{65: '’em', 67: 'them'}], [{65: '’ll', 67: 'will'}], [{65: '’nuff', 67: 'enough'}], [{65: 'y’', 67: 'you'}, {65: 'all'}], [{65: 'how'}, {65: '’d'}, {65: '’y', 67: 'you'}], [{65: 'How', 67: 'how'}, {65: '’d'}, {65: '’y', 67: 'you'}], [{65: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'Not', 67: 'not'}, {65: '’ve', 67: 'have'}], [{65: 'let'}, {65: '’s', 67: 'us'}], [{65: 'Let', 67: 'let'}, {65: '’s', 67: 'us'}], [{65: 'c’m', 67: 'come'}, {65: 'on'}], [{65: 'C’m', 67: 'come'}, {65: 'on'}], [{65: '’S', 67: \"'s\"}], [{65: '’s', 67: \"'s\"}], [{65: '’re', 67: 'are'}], [{65: '’Cause', 67: 'because'}], [{65: '’cause', 67: 'because'}], [{65: '’cos', 67: 'because'}], [{65: '’Cos', 67: 'because'}], [{65: '’coz', 67: 'because'}], [{65: '’Coz', 67: 'because'}], [{65: '’cuz', 67: 'because'}], [{65: '’Cuz', 67: 'because'}], [{65: '’bout', 67: 'about'}], [{65: 'ma’am', 67: 'madam'}], [{65: 'Ma’am', 67: 'madam'}], [{65: 'o’clock', 67: \"o'clock\"}], [{65: 'O’clock', 67: \"o'clock\"}], [{65: 'lovin’', 67: 'loving'}], [{65: 'Lovin’', 67: 'loving'}], [{65: 'havin’', 67: 'having'}], [{65: 'Havin’', 67: 'having'}], [{65: '’d'}]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en.tokenizer_exceptions import TOKENIZER_EXCEPTIONS\n",
    "\n",
    "TOKENIZER_EXCEPTIONS.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "excess-rebound",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.109723Z",
     "start_time": "2021-03-28T20:32:44.104174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "$\n",
      "STOCK.\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(\"This is a $STOCK.\")\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-adaptation",
   "metadata": {},
   "source": [
    "You can add special prefixes in the form of regex by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unlikely-croatia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.115930Z",
     "start_time": "2021-03-28T20:32:44.111815Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_prefixes = nlp.Defaults.prefixes + [r\"\\$[a-zA-Z]+\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "strategic-slovakia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.124436Z",
     "start_time": "2021-03-28T20:32:44.117070Z"
    }
   },
   "outputs": [],
   "source": [
    "prefix_re = spacy.util.compile_prefix_regex(custom_prefixes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "arabic-arena",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.134261Z",
     "start_time": "2021-03-28T20:32:44.125454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "$STOCK\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "prefix_re = re.compile(r\"\\$[a-zA-Z]+\")\n",
    "tokenizer = Tokenizer(\n",
    "    nlp.vocab, prefix_search=prefix_re.search, suffix_search=suffix_re.search\n",
    ")\n",
    "\n",
    "tokens = tokenizer(\"This is a $STOCK.\")\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-breed",
   "metadata": {},
   "source": [
    "You can add also special-case tokenization rules. This mechanism is also used to add custom tokenizer exceptions to the language data. See the usage guide on the [languages data](https://spacy.io/usage/linguistic-features#language-data) and [tokenizer special cases](https://spacy.io/usage/linguistic-features#special-cases) for more details and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dirty-chester",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.146952Z",
     "start_time": "2021-03-28T20:32:44.135427Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E997] Tokenizer special cases are not allowed to modify the text. This would map 'gimme' to 'gime' given token attributes '[{65: 'gi', 67: 'give'}, {65: 'me', 67: 'me'}]'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-b8c2c9d13842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgimme_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mORTH\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"gi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNORM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"give\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mORTH\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"me\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNORM\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"me\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_special_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"don't\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdont_case\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_special_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gimme\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgimme_case\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Yo! gimme five!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/MachineLearning/lib/python3.8/site-packages/spacy/tokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.add_special_case\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/MachineLearning/lib/python3.8/site-packages/spacy/tokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer._validate_special_case\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E997] Tokenizer special cases are not allowed to modify the text. This would map 'gimme' to 'gime' given token attributes '[{65: 'gi', 67: 'give'}, {65: 'me', 67: 'me'}]'."
     ]
    }
   ],
   "source": [
    "from spacy.attrs import ORTH, NORM, LOWER\n",
    "\n",
    "dont_case = [{ORTH: \"do\"}, {ORTH: \"n't\", NORM: \"not\"}]\n",
    "gimme_case = [{ORTH: \"gi\", NORM:\"give\"}, {ORTH: \"me\", NORM: \"me\"}]\n",
    "tokenizer.add_special_case(\"don't\", dont_case)\n",
    "tokenizer.add_special_case(\"gimme\", gimme_case)\n",
    "tokens = tokenizer(\"Yo! gimme five!\")\n",
    "for token in tokens:\n",
    "    print(token.norm_)\n",
    "tokens = tokenizer(\"You don't do that\")\n",
    "for token in tokens:\n",
    "    print(token.norm_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-checklist",
   "metadata": {},
   "source": [
    "When you load a model with pretrained NER (Named Entity Recognition), like `en_core_web_sm`, it is possible to make the tokenizer to merge the token for the entities it finds. Let's check what is inside the pipeline performed by `nlp`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "undefined-jesus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.151274Z",
     "start_time": "2021-03-28T20:32:44.148001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f7ba335fae0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7f7ba33404f0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f7ba3551f40>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f7ba3698ee0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f7ba3330980>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7f7ba331ffc0>)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-consumer",
   "metadata": {},
   "source": [
    "There's a tagger, a dependency parser and the entity recognizer. Let's check the entities of the following sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "sufficient-radar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.161196Z",
     "start_time": "2021-03-28T20:32:44.152194Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"Apple is a $1000b company.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "mighty-twenty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.166456Z",
     "start_time": "2021-03-28T20:32:44.162183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "a\n",
      "$\n",
      "1000b\n",
      "company\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "convenient-census",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.172302Z",
     "start_time": "2021-03-28T20:32:44.167426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "pregnant-working",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.200653Z",
     "start_time": "2021-03-28T20:32:44.178705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "Strive\n",
      "School\n",
      ".\n",
      "It\n",
      "'s\n",
      "worthy\n",
      "to\n",
      "merge\n",
      "'\n",
      "Strive\n",
      "School\n",
      "'\n",
      "as\n",
      "a\n",
      "single\n",
      "token\n",
      "instead\n",
      "of\n",
      "two\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\n",
    "    \"This is Strive School. It's worthy to merge 'Strive School' as a single token instead of two\"\n",
    ")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sweet-mandate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.207796Z",
     "start_time": "2021-03-28T20:32:44.203763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strive School ORG\n",
      "two CARDINAL\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-calculator",
   "metadata": {},
   "source": [
    "Let's add \"merge_entities\" to the pipeline (you can do it only if there is the entity recognizer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "laughing-military",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.212102Z",
     "start_time": "2021-03-28T20:32:44.208805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function spacy.pipeline.functions.merge_entities(doc: spacy.tokens.doc.Doc)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"merge_entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "standing-textbook",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.216239Z",
     "start_time": "2021-03-28T20:32:44.213031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f7ba335fae0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7f7ba33404f0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f7ba3551f40>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f7ba3698ee0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f7ba3330980>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7f7ba331ffc0>),\n",
       " ('merge_entities',\n",
       "  <function spacy.pipeline.functions.merge_entities(doc: spacy.tokens.doc.Doc)>)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "determined-montana",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.233121Z",
     "start_time": "2021-03-28T20:32:44.217083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "Strive School\n",
      ".\n",
      "It\n",
      "'s\n",
      "worthy\n",
      "to\n",
      "merge\n",
      "'\n",
      "Strive\n",
      "School\n",
      "'\n",
      "as\n",
      "a\n",
      "single\n",
      "token\n",
      "instead\n",
      "of\n",
      "two\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\n",
    "    \"This is Strive School. It's worthy to merge 'Strive School' as a single token instead of two\"\n",
    ")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "stretch-solution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.237660Z",
     "start_time": "2021-03-28T20:32:44.234118Z"
    }
   },
   "outputs": [],
   "source": [
    "TEXTS = [\n",
    "    \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
    "    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "informal-petite",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.257141Z",
     "start_time": "2021-03-28T20:32:44.238468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net\n",
      "income\n",
      "was\n",
      "$9.4 million\n",
      "compared\n",
      "to\n",
      "the prior year\n",
      "of\n",
      "$2.7 million\n",
      ".\n",
      "------------------\n",
      "Revenue\n",
      "exceeded\n",
      "twelve billion dollars\n",
      ",\n",
      "with\n",
      "a\n",
      "loss\n",
      "of\n",
      "$\n",
      "1b\n",
      ".\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "for sentence in nlp.pipe(TEXTS):\n",
    "    for token in sentence:\n",
    "        print(token)\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-maximum",
   "metadata": {},
   "source": [
    "It's also possible to merge the noun chunks into one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "possible-client",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.263274Z",
     "start_time": "2021-03-28T20:32:44.258469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function spacy.pipeline.functions.merge_noun_chunks(doc: spacy.tokens.doc.Doc) -> spacy.tokens.doc.Doc>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"merge_noun_chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "frozen-custody",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.268793Z",
     "start_time": "2021-03-28T20:32:44.264555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f7ba335fae0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7f7ba33404f0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f7ba3551f40>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f7ba3698ee0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f7ba3330980>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7f7ba331ffc0>),\n",
       " ('merge_entities',\n",
       "  <function spacy.pipeline.functions.merge_entities(doc: spacy.tokens.doc.Doc)>),\n",
       " ('merge_noun_chunks',\n",
       "  <function spacy.pipeline.functions.merge_noun_chunks(doc: spacy.tokens.doc.Doc) -> spacy.tokens.doc.Doc>)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "every-wedding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.282564Z",
     "start_time": "2021-03-28T20:32:44.269711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      ",\n",
      "I\n",
      "'m\n",
      "Antonio Marsella\n",
      ",\n",
      "nice\n",
      "to\n",
      "meet\n",
      "you\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Hello, I'm Antonio Marsella, nice to meet you.\")\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-cassette",
   "metadata": {},
   "source": [
    "## Removing stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-brief",
   "metadata": {},
   "source": [
    "In general, it's convenient to remove all the stop words, *i.e. very common words in a language*, because they don't help most of NLP problem such as semantic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "going-palace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.290058Z",
     "start_time": "2021-03-28T20:32:44.283484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 326\n",
      "First ten stop words: ['thence', 'whence', 'any', 'eleven', 'between', 'been', 'beforehand', 'whoever', 'however', 'another']\n"
     ]
    }
   ],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print(\"Number of stop words: %d\" % len(spacy_stopwords))\n",
    "print(\"First ten stop words: %s\" % list(spacy_stopwords)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-tokyo",
   "metadata": {},
   "source": [
    "To remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "crucial-entry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.317300Z",
     "start_time": "2021-03-28T20:32:44.291085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "determined\n",
      "drop\n",
      "his litigation\n",
      "the monastry\n",
      ",\n",
      "relinguish\n",
      "his claims\n",
      "the wood-cuting\n",
      "\n",
      "\n",
      "fishery rihgts\n",
      ".\n",
      "ready\n",
      "becuase\n",
      "the rights\n",
      "valuable\n",
      ",\n",
      "\n",
      "\n",
      "indeed the vaguest idea\n",
      "the wood\n",
      "river\n",
      "question\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "tokens = [token.text for token in doc if not token.is_stop]\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-death",
   "metadata": {},
   "source": [
    "For adding customized stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acknowledged-bahamas",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:33:30.546200Z",
     "start_time": "2021-03-28T20:33:30.528780Z"
    }
   },
   "outputs": [],
   "source": [
    "customize_stop_words = [\"computing\", \"filtered\"]\n",
    "for w in customize_stop_words:\n",
    "    nlp.vocab[w].is_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-scene",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization\n",
    "\n",
    "In most natural languages, a root word can have many variants. For example, the word ‘play’ can be used as ‘playing’, ‘played’, ‘plays’, etc. You can think of similar examples (and there are plenty).\n",
    "\n",
    "**Stemming**\n",
    "\n",
    "Let’s first understand stemming:\n",
    "\n",
    "Stemming is a text normalization technique that cuts off the end or beginning of a word by taking into account a list of common prefixes or suffixes that could be found in that word\n",
    "It is a rudimentary rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “s” etc) from a word\n",
    " \n",
    "\n",
    "**Lemmatization**\n",
    "\n",
    "Lemmatization, on the other hand, is an organized & step-by-step procedure of obtaining the root form of the word. It makes use of vocabulary (dictionary importance of words) and morphological analysis (word structure and grammar relations).\n",
    "\n",
    "Stemming algorithm works by cutting the suffix or prefix from the word. Lemmatization is a more powerful operation as it takes into consideration the morphological analysis of the word.\n",
    "\n",
    "Lemmatization returns the lemma, which is the root word of all its inflection forms.\n",
    "\n",
    "We can say that stemming is a quick and dirty method of chopping off words to its root form while on the other hand, lemmatization is an intelligent operation that uses dictionaries which are created by in-depth linguistic knowledge. Hence, Lemmatization helps in forming better features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "worthy-toilet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:33:36.947990Z",
     "start_time": "2021-03-28T20:33:36.465998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['determine',\n",
       " 'drop',\n",
       " 'litigation',\n",
       " 'monastry',\n",
       " ',',\n",
       " 'relinguish',\n",
       " 'claim',\n",
       " 'wood',\n",
       " '-',\n",
       " 'cuting',\n",
       " '\\n',\n",
       " 'fishery',\n",
       " 'rihgts',\n",
       " '.',\n",
       " 'ready',\n",
       " 'becuase',\n",
       " 'right',\n",
       " 'valuable',\n",
       " ',',\n",
       " '\\n',\n",
       " 'vague',\n",
       " 'idea',\n",
       " 'wood',\n",
       " 'river',\n",
       " 'question',\n",
       " '.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"merge_entities\")\n",
    "# not using merge_chunk_nouns\n",
    "doc = nlp(\n",
    "    u\"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
    ")\n",
    "\n",
    "lemma_word1 = []\n",
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        continue\n",
    "    lemma_word1.append(token.lemma_)\n",
    "lemma_word1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-large",
   "metadata": {},
   "source": [
    "## Removing the punctuation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "tested-lafayette",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:33:38.236544Z",
     "start_time": "2021-03-28T20:33:38.220156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He determined to drop his litigation with the monastry and relinguish his claims to the woodcuting and \\nfishery rihgts at once He was the more ready to do this becuase the rights had become much less valuable and he had \\nindeed the vaguest idea where the wood and river in question were'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
    "\n",
    "\n",
    "import string\n",
    "\n",
    "text_no_punct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "text_no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "institutional-commerce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:33:38.840465Z",
     "start_time": "2021-03-28T20:33:38.808474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n",
      "determined\n",
      "to\n",
      "drop\n",
      "his\n",
      "litigation\n",
      "with\n",
      "the\n",
      "monastry\n",
      "and\n",
      "relinguish\n",
      "his\n",
      "claims\n",
      "to\n",
      "the\n",
      "woodcuting\n",
      "and\n",
      "\n",
      "\n",
      "fishery\n",
      "rihgts\n",
      "at\n",
      "once\n",
      "He\n",
      "was\n",
      "the\n",
      "more\n",
      "ready\n",
      "to\n",
      "do\n",
      "this\n",
      "becuase\n",
      "the\n",
      "rights\n",
      "had\n",
      "become\n",
      "much\n",
      "less\n",
      "valuable\n",
      "and\n",
      "he\n",
      "had\n",
      "\n",
      "\n",
      "indeed\n",
      "the\n",
      "vaguest\n",
      "idea\n",
      "where\n",
      "the\n",
      "wood\n",
      "and\n",
      "river\n",
      "in\n",
      "question\n",
      "were\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text_no_punct)\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-source",
   "metadata": {},
   "source": [
    "For text extracted from dialogues or chats, it is convenient to preprocess the text so that multiple occurrences of the same characters get condensed into one or two, and then use a spell checker to find the correct form of the word.\n",
    "\n",
    "A way to do that is to replace all the occurrences of repeated characters with a single one and then use a spell checker: \"hhheeelllllooo hoooowww areee youuu?\" becomes \"helo how are you?\" and then the spell checker would make it \"hello how are you?\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "greater-cabin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:44:46.506377Z",
     "start_time": "2021-03-28T20:44:46.492492Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'heLo how are you?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = \"hhheeeLLLLooo hoooowww areee youuu?????\"\n",
    "text = re.sub(r\"(.)\\1+\", r\"\\1\", st)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "imported-hartford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autocorrect\n",
      "  Downloading autocorrect-2.3.0.tar.gz (621 kB)\n",
      "\u001b[K     |████████████████████████████████| 621 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
      "  Building wheel for autocorrect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.3.0-py3-none-any.whl size=621586 sha256=32ae51b3f669f19a7a2cc0d2d5103e9d672bdc9bd6eed32f40a374f5982225f3\n",
      "  Stored in directory: /home/roy/.cache/pip/wheels/fe/6e/8a/4e8bafec0225cfbdf79a0da722b691e4dc5d20d197423e8b28\n",
      "Successfully built autocorrect\n",
      "Installing collected packages: autocorrect\n",
      "Successfully installed autocorrect-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "monthly-rapid",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:44:48.622525Z",
     "start_time": "2021-03-28T20:44:48.518501Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'indexer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-3ed301ccfd37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspellchecker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mspell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/MachineLearning/lib/python3.8/site-packages/spellchecker/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m  \u001b[0mspellchecker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpellchecker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgetInstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/MachineLearning/lib/python3.8/site-packages/spellchecker/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictionaryIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangdetect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_detect_lang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'indexer'"
     ]
    }
   ],
   "source": [
    "from autocorrect import SpellChecker\n",
    "\n",
    "text = nlp(text)\n",
    "spell = SpellChecker()\n",
    "\n",
    "# find those words that may be misspelled\n",
    "misspelled = spell.unknown([token.text for token in text])\n",
    "\n",
    "for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))\n",
    "\n",
    "    # Get a list of `likely` options\n",
    "    print(spell.candidates(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-marriage",
   "metadata": {},
   "source": [
    "It didn't find any mispelled (even if there was \"helo\"). Try another spell checker:\n",
    "\n",
    "https://github.com/fsondej/autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "terminal-occupation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:43:37.953727Z",
     "start_time": "2021-03-28T20:43:37.889573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hero how are you?'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller()\n",
    "text = nlp(text)\n",
    "spell(text.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-language",
   "metadata": {},
   "source": [
    "As you can see, it's not always working properly! However, overall it should improve your text.\n",
    "\n",
    "If you want to create a separate lemmatizer instead of having it in the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "false-portrait",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:50:55.492317Z",
     "start_time": "2021-03-28T20:50:55.486168Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy.lemmatizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-d0cf66c47445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLemmatizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mADJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNOUN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVERB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlemmatizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"studying\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVERB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"studying\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNOUN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy.lemmatizer'"
     ]
    }
   ],
   "source": [
    "from spacy.lemmatizer import Lemmatizer, ADJ, NOUN, VERB\n",
    "\n",
    "lemmatizer = nlp.vocab.morphology.lemmatizer\n",
    "print(lemmatizer(\"studying\", VERB))\n",
    "print(lemmatizer(\"studying\", NOUN))\n",
    "print(lemmatizer(\"studying\", ADJ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "civil-sterling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:52:21.406926Z",
     "start_time": "2021-03-28T20:52:21.398539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lexeme_norm']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.lookups.tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-header",
   "metadata": {},
   "source": [
    "spaCy has no built-in stemming! However, Lemmatization is enough for most of the tasks. As alternative, you can use [NLTK library](https://www.nltk.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-chart",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "A named entity is a “real-world object” that’s assigned a name – for example, a person, a country, a product or a book title. spaCy can recognize various types of named entities in a document, by asking the model for a prediction. Because models are statistical and strongly depend on the examples they were trained on, this doesn’t always work perfectly and might need some tuning later, depending on your use case.\n",
    "\n",
    "Named entities are available as the ents property of a Doc.\n",
    "\n",
    "\n",
    "Example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "pacific-generation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T06:04:34.612659Z",
     "start_time": "2021-03-29T06:04:34.586397Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"Antonio works at Strive School.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "prescription-swimming",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T06:04:49.092105Z",
     "start_time": "2021-03-29T06:04:49.075027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Antonio works at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Strive School\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "substantial-bookmark",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T06:06:02.488436Z",
     "start_time": "2021-03-29T06:06:02.459044Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"Rome is a big city.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "organized-reservoir",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T06:06:05.912053Z",
     "start_time": "2021-03-29T06:06:05.901532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rome\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is a big city.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-gospel",
   "metadata": {},
   "source": [
    "ORG stands for organization, GPE stands for Geopolitical Entity. Some other tags are:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
